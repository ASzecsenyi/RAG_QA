{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:53:19.268335300Z",
     "start_time": "2024-02-24T10:53:17.811874600Z"
    }
   },
   "id": "3f8a911effd996b7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:53:20.083330300Z",
     "start_time": "2024-02-24T10:53:20.073322400Z"
    }
   },
   "id": "a36877d59378936c",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'validation', 'test'])\n",
      "{   'abstract': 'Recognizing affective events that trigger positive or '\n",
      "                'negative sentiment has a wide range of natural language '\n",
      "                'processing applications but remains a challenging problem '\n",
      "                'mainly because the polarity of an event is not necessarily '\n",
      "                'predictable from its constituent words. In this paper, we '\n",
      "                'propose to propagate affective polarity using discourse '\n",
      "                'relations. Our method is simple and only requires a very '\n",
      "                'small seed lexicon and a large raw corpus. Our experiments '\n",
      "                'using Japanese data show that our method learns affective '\n",
      "                'events effectively without manually labeled data. It also '\n",
      "                'improves supervised learning results when labeled data are '\n",
      "                'small.',\n",
      "    'figures_and_tables': {   'caption': [   'Figure 1: An overview of our '\n",
      "                                             'method. We focus on pairs of '\n",
      "                                             'events, the former events and '\n",
      "                                             'the latter events, which are '\n",
      "                                             'connected with a discourse '\n",
      "                                             'relation, CAUSE or CONCESSION. '\n",
      "                                             'Dropped pronouns are indicated '\n",
      "                                             'by brackets in English '\n",
      "                                             'translations. We divide the '\n",
      "                                             'event pairs into three types: '\n",
      "                                             'AL, CA, and CO. In AL, the '\n",
      "                                             'polarity of a latter event is '\n",
      "                                             'automatically identified as '\n",
      "                                             'either positive or negative, '\n",
      "                                             'according to the seed lexicon '\n",
      "                                             '(the positive word is colored '\n",
      "                                             'red and the negative word blue). '\n",
      "                                             'We propagate the latter event’s '\n",
      "                                             'polarity to the former event. '\n",
      "                                             'The same polarity as the latter '\n",
      "                                             'event is used for the discourse '\n",
      "                                             'relation CAUSE, and the reversed '\n",
      "                                             'polarity for CONCESSION. In CA '\n",
      "                                             'and CO, the latter event’s '\n",
      "                                             'polarity is not known. Depending '\n",
      "                                             'on the discourse relation, we '\n",
      "                                             'encourage the two events’ '\n",
      "                                             'polarities to be the same (CA) '\n",
      "                                             'or reversed (CO). Details are '\n",
      "                                             'given in Section 3.2.',\n",
      "                                             'Table 1: Statistics of the AL, '\n",
      "                                             'CA, and CO datasets.',\n",
      "                                             'Table 2: Details of the ACP '\n",
      "                                             'dataset.',\n",
      "                                             'Table 5: Examples of polarity '\n",
      "                                             'scores predicted by the BiGRU '\n",
      "                                             'model trained with AL+CA+CO.',\n",
      "                                             'Table 3: Performance of various '\n",
      "                                             'models on the ACP test set.',\n",
      "                                             'Table 4: Results for small '\n",
      "                                             'labeled training data. Given the '\n",
      "                                             'performance with the full '\n",
      "                                             'dataset, we show BERT trained '\n",
      "                                             'only with the AL data.'],\n",
      "                              'file': [   '2-Figure1-1.png',\n",
      "                                          '4-Table1-1.png',\n",
      "                                          '4-Table2-1.png',\n",
      "                                          '5-Table5-1.png',\n",
      "                                          '5-Table3-1.png',\n",
      "                                          '5-Table4-1.png']},\n",
      "    'full_text': {   'paragraphs': [   [   'Affective events BIBREF0 are '\n",
      "                                           'events that typically affect '\n",
      "                                           'people in positive or negative '\n",
      "                                           'ways. For example, getting money '\n",
      "                                           'and playing sports are usually '\n",
      "                                           'positive to the experiencers; '\n",
      "                                           \"catching cold and losing one's \"\n",
      "                                           'wallet are negative. Understanding '\n",
      "                                           'affective events is important to '\n",
      "                                           'various natural language '\n",
      "                                           'processing (NLP) applications such '\n",
      "                                           'as dialogue systems BIBREF1, '\n",
      "                                           'question-answering systems '\n",
      "                                           'BIBREF2, and humor recognition '\n",
      "                                           'BIBREF3. In this paper, we work on '\n",
      "                                           'recognizing the polarity of an '\n",
      "                                           'affective event that is '\n",
      "                                           'represented by a score ranging '\n",
      "                                           'from $-1$ (negative) to 1 '\n",
      "                                           '(positive).',\n",
      "                                           'Learning affective events is '\n",
      "                                           'challenging because, as the '\n",
      "                                           'examples above suggest, the '\n",
      "                                           'polarity of an event is not '\n",
      "                                           'necessarily predictable from its '\n",
      "                                           'constituent words. Combined with '\n",
      "                                           'the unbounded combinatorial nature '\n",
      "                                           'of language, the '\n",
      "                                           'non-compositionality of affective '\n",
      "                                           'polarity entails the need for '\n",
      "                                           'large amounts of world knowledge, '\n",
      "                                           'which can hardly be learned from '\n",
      "                                           'small annotated data.',\n",
      "                                           'In this paper, we propose a simple '\n",
      "                                           'and effective method for learning '\n",
      "                                           'affective events that only '\n",
      "                                           'requires a very small seed lexicon '\n",
      "                                           'and a large raw corpus. As '\n",
      "                                           'illustrated in Figure FIGREF1, our '\n",
      "                                           'key idea is that we can exploit '\n",
      "                                           'discourse relations BIBREF4 to '\n",
      "                                           'efficiently propagate polarity '\n",
      "                                           'from seed predicates that directly '\n",
      "                                           \"report one's emotions (e.g., “to \"\n",
      "                                           'be glad” is positive). Suppose '\n",
      "                                           'that events $x_1$ are $x_2$ are in '\n",
      "                                           'the discourse relation of Cause '\n",
      "                                           '(i.e., $x_1$ causes $x_2$). If the '\n",
      "                                           'seed lexicon suggests $x_2$ is '\n",
      "                                           'positive, $x_1$ is also likely to '\n",
      "                                           'be positive because it triggers '\n",
      "                                           'the positive emotion. The fact '\n",
      "                                           'that $x_2$ is known to be negative '\n",
      "                                           'indicates the negative polarity of '\n",
      "                                           '$x_1$. Similarly, if $x_1$ and '\n",
      "                                           '$x_2$ are in the discourse '\n",
      "                                           'relation of Concession (i.e., '\n",
      "                                           '$x_2$ in spite of $x_1$), the '\n",
      "                                           \"reverse of $x_2$'s polarity can be \"\n",
      "                                           'propagated to $x_1$. Even if '\n",
      "                                           \"$x_2$'s polarity is not known in \"\n",
      "                                           'advance, we can exploit the '\n",
      "                                           'tendency of $x_1$ and $x_2$ to be '\n",
      "                                           'of the same polarity (for Cause) '\n",
      "                                           'or of the reverse polarity (for '\n",
      "                                           'Concession) although the heuristic '\n",
      "                                           'is not exempt from '\n",
      "                                           'counterexamples. We transform this '\n",
      "                                           'idea into objective functions and '\n",
      "                                           'train neural network models that '\n",
      "                                           'predict the polarity of a given '\n",
      "                                           'event.',\n",
      "                                           'We trained the models using a '\n",
      "                                           'Japanese web corpus. Given the '\n",
      "                                           'minimum amount of supervision, '\n",
      "                                           'they performed well. In addition, '\n",
      "                                           'the combination of annotated and '\n",
      "                                           'unannotated data yielded a gain '\n",
      "                                           'over a purely supervised baseline '\n",
      "                                           'when labeled data were small.'],\n",
      "                                       [   'Learning affective events is '\n",
      "                                           'closely related to sentiment '\n",
      "                                           'analysis. Whereas sentiment '\n",
      "                                           'analysis usually focuses on the '\n",
      "                                           'polarity of what are described '\n",
      "                                           '(e.g., movies), we work on how '\n",
      "                                           'people are typically affected by '\n",
      "                                           'events. In sentiment analysis, '\n",
      "                                           'much attention has been paid to '\n",
      "                                           'compositionality. Word-level '\n",
      "                                           'polarity BIBREF5, BIBREF6, BIBREF7 '\n",
      "                                           'and the roles of negation and '\n",
      "                                           'intensification BIBREF8, BIBREF6, '\n",
      "                                           'BIBREF9 are among the most '\n",
      "                                           'important topics. In contrast, we '\n",
      "                                           'are more interested in recognizing '\n",
      "                                           'the sentiment polarity of an event '\n",
      "                                           'that pertains to commonsense '\n",
      "                                           'knowledge (e.g., getting money and '\n",
      "                                           'catching cold).',\n",
      "                                           'Label propagation from seed '\n",
      "                                           'instances is a common approach to '\n",
      "                                           'inducing sentiment polarities. '\n",
      "                                           'While BIBREF5 and BIBREF10 worked '\n",
      "                                           'on word- and phrase-level '\n",
      "                                           'polarities, BIBREF0 dealt with '\n",
      "                                           'event-level polarities. BIBREF5 '\n",
      "                                           'and BIBREF10 linked instances '\n",
      "                                           'using co-occurrence information '\n",
      "                                           'and/or phrase-level coordinations '\n",
      "                                           '(e.g., “$A$ and $B$” and “$A$ but '\n",
      "                                           '$B$”). We shift our scope to event '\n",
      "                                           'pairs that are more complex than '\n",
      "                                           'phrase pairs, and consequently '\n",
      "                                           'exploit discourse connectives as '\n",
      "                                           'event-level counterparts of '\n",
      "                                           'phrase-level conjunctions.',\n",
      "                                           'BIBREF0 constructed a network of '\n",
      "                                           'events using word '\n",
      "                                           'embedding-derived similarities. '\n",
      "                                           'Compared with this method, our '\n",
      "                                           'discourse relation-based linking '\n",
      "                                           'of events is much simpler and more '\n",
      "                                           'intuitive.',\n",
      "                                           'Some previous studies made use of '\n",
      "                                           'document structure to understand '\n",
      "                                           'the sentiment. BIBREF11 proposed a '\n",
      "                                           'sentiment-specific pre-training '\n",
      "                                           'strategy using unlabeled dialog '\n",
      "                                           'data (tweet-reply pairs). BIBREF12 '\n",
      "                                           'proposed a method of building a '\n",
      "                                           'polarity-tagged corpus (ACP '\n",
      "                                           'Corpus). They automatically '\n",
      "                                           'gathered sentences that had '\n",
      "                                           'positive or negative opinions '\n",
      "                                           'utilizing HTML layout structures '\n",
      "                                           'in addition to linguistic '\n",
      "                                           'patterns. Our method depends only '\n",
      "                                           'on raw texts and thus has wider '\n",
      "                                           'applicability.',\n",
      "                                           ''],\n",
      "                                       [''],\n",
      "                                       [   '',\n",
      "                                           'Our goal is to learn the polarity '\n",
      "                                           'function $p(x)$, which predicts '\n",
      "                                           'the sentiment polarity score of an '\n",
      "                                           'event $x$. We approximate $p(x)$ '\n",
      "                                           'by a neural network with the '\n",
      "                                           'following form:',\n",
      "                                           '${\\\\rm Encoder}$ outputs a vector '\n",
      "                                           'representation of the event $x$. '\n",
      "                                           '${\\\\rm Linear}$ is a '\n",
      "                                           'fully-connected layer and '\n",
      "                                           'transforms the representation into '\n",
      "                                           'a scalar. ${\\\\rm tanh}$ is the '\n",
      "                                           'hyperbolic tangent and transforms '\n",
      "                                           'the scalar into a score ranging '\n",
      "                                           'from $-1$ to 1. In Section '\n",
      "                                           'SECREF21, we consider two specific '\n",
      "                                           'implementations of ${\\\\rm '\n",
      "                                           'Encoder}$.',\n",
      "                                           ''],\n",
      "                                       [   'Our method requires a very small '\n",
      "                                           'seed lexicon and a large raw '\n",
      "                                           'corpus. We assume that we can '\n",
      "                                           'automatically extract '\n",
      "                                           'discourse-tagged event pairs, '\n",
      "                                           '$(x_{i1}, x_{i2})$ ($i=1, \\\\cdots '\n",
      "                                           '$) from the raw corpus. We refer '\n",
      "                                           'to $x_{i1}$ and $x_{i2}$ as former '\n",
      "                                           'and latter events, respectively. '\n",
      "                                           'As shown in Figure FIGREF1, we '\n",
      "                                           'limit our scope to two discourse '\n",
      "                                           'relations: Cause and Concession.',\n",
      "                                           'The seed lexicon consists of '\n",
      "                                           'positive and negative predicates. '\n",
      "                                           'If the predicate of an extracted '\n",
      "                                           'event is in the seed lexicon and '\n",
      "                                           'does not involve complex phenomena '\n",
      "                                           'like negation, we assign the '\n",
      "                                           'corresponding polarity score ($+1$ '\n",
      "                                           'for positive events and $-1$ for '\n",
      "                                           'negative events) to the event. We '\n",
      "                                           'expect the model to automatically '\n",
      "                                           'learn complex phenomena through '\n",
      "                                           'label propagation. Based on the '\n",
      "                                           'availability of scores and the '\n",
      "                                           'types of discourse relations, we '\n",
      "                                           'classify the extracted event pairs '\n",
      "                                           'into the following three types.',\n",
      "                                           ''],\n",
      "                                       [   'The seed lexicon matches (1) the '\n",
      "                                           'latter event but (2) not the '\n",
      "                                           'former event, and (3) their '\n",
      "                                           'discourse relation type is Cause '\n",
      "                                           'or Concession. If the discourse '\n",
      "                                           'relation type is Cause, the former '\n",
      "                                           'event is given the same score as '\n",
      "                                           'the latter. Likewise, if the '\n",
      "                                           'discourse relation type is '\n",
      "                                           'Concession, the former event is '\n",
      "                                           \"given the opposite of the latter's \"\n",
      "                                           'score. They are used as reference '\n",
      "                                           'scores during training.',\n",
      "                                           ''],\n",
      "                                       [   'The seed lexicon matches neither '\n",
      "                                           'the former nor the latter event, '\n",
      "                                           'and their discourse relation type '\n",
      "                                           'is Cause. We assume the two events '\n",
      "                                           'have the same polarities.',\n",
      "                                           ''],\n",
      "                                       [   'The seed lexicon matches neither '\n",
      "                                           'the former nor the latter event, '\n",
      "                                           'and their discourse relation type '\n",
      "                                           'is Concession. We assume the two '\n",
      "                                           'events have the reversed '\n",
      "                                           'polarities.',\n",
      "                                           ''],\n",
      "                                       [   'Using AL, CA, and CO data, we '\n",
      "                                           'optimize the parameters of the '\n",
      "                                           'polarity function $p(x)$. We '\n",
      "                                           'define a loss function for each of '\n",
      "                                           'the three types of event pairs and '\n",
      "                                           'sum up the multiple loss '\n",
      "                                           'functions.',\n",
      "                                           'We use mean squared error to '\n",
      "                                           'construct loss functions. For the '\n",
      "                                           'AL data, the loss function is '\n",
      "                                           'defined as:',\n",
      "                                           'where $x_{i1}$ and $x_{i2}$ are '\n",
      "                                           'the $i$-th pair of the AL data. '\n",
      "                                           '$r_{i1}$ and $r_{i2}$ are the '\n",
      "                                           'automatically-assigned scores of '\n",
      "                                           '$x_{i1}$ and $x_{i2}$, '\n",
      "                                           'respectively. $N_{\\\\rm AL}$ is the '\n",
      "                                           'total number of AL pairs, and '\n",
      "                                           '$\\\\lambda _{\\\\rm AL}$ is a '\n",
      "                                           'hyperparameter.',\n",
      "                                           'For the CA data, the loss function '\n",
      "                                           'is defined as:',\n",
      "                                           '$y_{i1}$ and $y_{i2}$ are the '\n",
      "                                           '$i$-th pair of the CA pairs. '\n",
      "                                           '$N_{\\\\rm CA}$ is the total number '\n",
      "                                           'of CA pairs. $\\\\lambda _{\\\\rm CA}$ '\n",
      "                                           'and $\\\\mu $ are hyperparameters. '\n",
      "                                           'The first term makes the scores of '\n",
      "                                           'the two events closer while the '\n",
      "                                           'second term prevents the scores '\n",
      "                                           'from shrinking to zero.',\n",
      "                                           'The loss function for the CO data '\n",
      "                                           'is defined analogously:',\n",
      "                                           'The difference is that the first '\n",
      "                                           'term makes the scores of the two '\n",
      "                                           'events distant from each other.',\n",
      "                                           ''],\n",
      "                                       [''],\n",
      "                                       [''],\n",
      "                                       [   'As a raw corpus, we used a '\n",
      "                                           'Japanese web corpus that was '\n",
      "                                           'compiled through the procedures '\n",
      "                                           'proposed by BIBREF13. To extract '\n",
      "                                           'event pairs tagged with discourse '\n",
      "                                           'relations, we used the Japanese '\n",
      "                                           'dependency parser KNP and in-house '\n",
      "                                           'postprocessing scripts BIBREF14. '\n",
      "                                           'KNP used hand-written rules to '\n",
      "                                           'segment each sentence into what we '\n",
      "                                           'conventionally called clauses '\n",
      "                                           '(mostly consecutive text chunks), '\n",
      "                                           'each of which contained one main '\n",
      "                                           'predicate. KNP also identified the '\n",
      "                                           'discourse relations of event pairs '\n",
      "                                           'if explicit discourse connectives '\n",
      "                                           'BIBREF4 such as “ので” (because) and '\n",
      "                                           '“のに” (in spite of) were present. '\n",
      "                                           'We treated Cause/Reason (原因・理由) '\n",
      "                                           'and Condition (条件) in the original '\n",
      "                                           'tagset BIBREF15 as Cause and '\n",
      "                                           'Concession (逆接) as Concession, '\n",
      "                                           'respectively. Here is an example '\n",
      "                                           'of event pair extraction.',\n",
      "                                           '. 重大な失敗を犯したので、仕事をクビになった。',\n",
      "                                           'Because [I] made a serious '\n",
      "                                           'mistake, [I] got fired.',\n",
      "                                           'From this sentence, we extracted '\n",
      "                                           'the event pair of “重大な失敗を犯す” ([I] '\n",
      "                                           'make a serious mistake) and '\n",
      "                                           '“仕事をクビになる” ([I] get fired), and '\n",
      "                                           'tagged it with Cause.',\n",
      "                                           'We constructed our seed lexicon '\n",
      "                                           'consisting of 15 positive words '\n",
      "                                           'and 15 negative words, as shown in '\n",
      "                                           'Section SECREF27. From the corpus '\n",
      "                                           'of about 100 million sentences, we '\n",
      "                                           'obtained 1.4 millions event pairs '\n",
      "                                           'for AL, 41 millions for CA, and 6 '\n",
      "                                           'millions for CO. We randomly '\n",
      "                                           'selected subsets of AL event pairs '\n",
      "                                           'such that positive and negative '\n",
      "                                           'latter events were equal in size. '\n",
      "                                           'We also sampled event pairs for '\n",
      "                                           'each of CA and CO such that it was '\n",
      "                                           'five times larger than AL. The '\n",
      "                                           'results are shown in Table '\n",
      "                                           'TABREF16.'],\n",
      "                                       [   'We used the latest version of the '\n",
      "                                           'ACP Corpus BIBREF12 for '\n",
      "                                           'evaluation. It was used for '\n",
      "                                           '(semi-)supervised training as '\n",
      "                                           'well. Extracted from Japanese '\n",
      "                                           'websites using HTML layouts and '\n",
      "                                           'linguistic patterns, the dataset '\n",
      "                                           'covered various genres. For '\n",
      "                                           'example, the following two '\n",
      "                                           'sentences were labeled positive '\n",
      "                                           'and negative, respectively:',\n",
      "                                           '. 作業が楽だ。',\n",
      "                                           'The work is easy.',\n",
      "                                           '. 駐車場がない。',\n",
      "                                           'There is no parking lot.',\n",
      "                                           'Although the ACP corpus was '\n",
      "                                           'originally constructed in the '\n",
      "                                           'context of sentiment analysis, we '\n",
      "                                           'found that it could roughly be '\n",
      "                                           'regarded as a collection of '\n",
      "                                           'affective events. We parsed each '\n",
      "                                           'sentence and extracted the last '\n",
      "                                           'clause in it. The train/dev/test '\n",
      "                                           'split of the data is shown in '\n",
      "                                           'Table TABREF19.',\n",
      "                                           'The objective function for '\n",
      "                                           'supervised training is:',\n",
      "                                           '',\n",
      "                                           'where $v_i$ is the $i$-th event, '\n",
      "                                           '$R_i$ is the reference score of '\n",
      "                                           '$v_i$, and $N_{\\\\rm ACP}$ is the '\n",
      "                                           'number of the events of the ACP '\n",
      "                                           'Corpus.',\n",
      "                                           'To optimize the hyperparameters, '\n",
      "                                           'we used the dev set of the ACP '\n",
      "                                           'Corpus. For the evaluation, we '\n",
      "                                           'used the test set of the ACP '\n",
      "                                           'Corpus. The model output was '\n",
      "                                           'classified as positive if $p(x) > '\n",
      "                                           '0$ and negative if $p(x) \\\\le 0$.',\n",
      "                                           ''],\n",
      "                                       [   'As for ${\\\\rm Encoder}$, we '\n",
      "                                           'compared two types of neural '\n",
      "                                           'networks: BiGRU and BERT. GRU '\n",
      "                                           'BIBREF16 is a recurrent neural '\n",
      "                                           'network sequence encoder. BiGRU '\n",
      "                                           'reads an input sequence forward '\n",
      "                                           'and backward and the output is the '\n",
      "                                           'concatenation of the final forward '\n",
      "                                           'and backward hidden states.',\n",
      "                                           'BERT BIBREF17 is a pre-trained '\n",
      "                                           'multi-layer bidirectional '\n",
      "                                           'Transformer BIBREF18 encoder. Its '\n",
      "                                           'output is the final hidden state '\n",
      "                                           'corresponding to the special '\n",
      "                                           'classification tag ([CLS]). For '\n",
      "                                           'the details of ${\\\\rm Encoder}$, '\n",
      "                                           'see Sections SECREF30.',\n",
      "                                           'We trained the model with the '\n",
      "                                           'following four combinations of the '\n",
      "                                           'datasets: AL, AL+CA+CO (two '\n",
      "                                           'proposed models), ACP '\n",
      "                                           '(supervised), and ACP+AL+CA+CO '\n",
      "                                           '(semi-supervised). The '\n",
      "                                           'corresponding objective functions '\n",
      "                                           'were: $\\\\mathcal {L}_{\\\\rm AL}$, '\n",
      "                                           '$\\\\mathcal {L}_{\\\\rm AL} + '\n",
      "                                           '\\\\mathcal {L}_{\\\\rm CA} + '\n",
      "                                           '\\\\mathcal {L}_{\\\\rm CO}$, '\n",
      "                                           '$\\\\mathcal {L}_{\\\\rm ACP}$, and '\n",
      "                                           '$\\\\mathcal {L}_{\\\\rm ACP} + '\n",
      "                                           '\\\\mathcal {L}_{\\\\rm AL} + '\n",
      "                                           '\\\\mathcal {L}_{\\\\rm CA} + '\n",
      "                                           '\\\\mathcal {L}_{\\\\rm CO}$.',\n",
      "                                           ''],\n",
      "                                       [   '',\n",
      "                                           'Table TABREF23 shows accuracy. As '\n",
      "                                           'the Random baseline suggests, '\n",
      "                                           'positive and negative labels were '\n",
      "                                           'distributed evenly. The '\n",
      "                                           'Random+Seed baseline made use of '\n",
      "                                           'the seed lexicon and output the '\n",
      "                                           'corresponding label (or the '\n",
      "                                           'reverse of it for negation) if the '\n",
      "                                           \"event's predicate is in the seed \"\n",
      "                                           'lexicon. We can see that the seed '\n",
      "                                           'lexicon itself had practically no '\n",
      "                                           'impact on prediction.',\n",
      "                                           'The models in the top block '\n",
      "                                           'performed considerably better than '\n",
      "                                           'the random baselines. The '\n",
      "                                           'performance gaps with their '\n",
      "                                           '(semi-)supervised counterparts, '\n",
      "                                           'shown in the middle block, were '\n",
      "                                           'less than 7%. This demonstrates '\n",
      "                                           'the effectiveness of discourse '\n",
      "                                           'relation-based label propagation.',\n",
      "                                           'Comparing the model variants, we '\n",
      "                                           'obtained the highest score with '\n",
      "                                           'the BiGRU encoder trained with the '\n",
      "                                           'AL+CA+CO dataset. BERT was '\n",
      "                                           'competitive but its performance '\n",
      "                                           'went down if CA and CO were used '\n",
      "                                           'in addition to AL. We conjecture '\n",
      "                                           'that BERT was more sensitive to '\n",
      "                                           'noises found more frequently in CA '\n",
      "                                           'and CO.',\n",
      "                                           'Contrary to our expectations, '\n",
      "                                           'supervised models (ACP) '\n",
      "                                           'outperformed semi-supervised '\n",
      "                                           'models (ACP+AL+CA+CO). This '\n",
      "                                           'suggests that the training set of '\n",
      "                                           '0.6 million events is sufficiently '\n",
      "                                           'large for training the models. For '\n",
      "                                           'comparison, we trained the models '\n",
      "                                           'with a subset (6,000 events) of '\n",
      "                                           'the ACP dataset. As the results '\n",
      "                                           'shown in Table TABREF24 '\n",
      "                                           'demonstrate, our method is '\n",
      "                                           'effective when labeled data are '\n",
      "                                           'small.',\n",
      "                                           'The result of hyperparameter '\n",
      "                                           'optimization for the BiGRU encoder '\n",
      "                                           'was as follows:',\n",
      "                                           'As the CA and CO pairs were equal '\n",
      "                                           'in size (Table TABREF16), '\n",
      "                                           '$\\\\lambda _{\\\\rm CA}$ and '\n",
      "                                           '$\\\\lambda _{\\\\rm CO}$ were '\n",
      "                                           'comparable values. $\\\\lambda '\n",
      "                                           '_{\\\\rm CA}$ was about one-third of '\n",
      "                                           '$\\\\lambda _{\\\\rm CO}$, and this '\n",
      "                                           'indicated that the CA pairs were '\n",
      "                                           'noisier than the CO pairs. A major '\n",
      "                                           'type of CA pairs that violates our '\n",
      "                                           'assumption was in the form of '\n",
      "                                           '“$\\\\textit '\n",
      "                                           '{problem}_{\\\\text{negative}}$ '\n",
      "                                           'causes $\\\\textit '\n",
      "                                           '{solution}_{\\\\text{positive}}$”:',\n",
      "                                           '. (悪いところがある, よくなるように努力する)',\n",
      "                                           '(there is a bad point, [I] try to '\n",
      "                                           'improve [it])',\n",
      "                                           'The polarities of the two events '\n",
      "                                           'were reversed in spite of the '\n",
      "                                           'Cause relation, and this lowered '\n",
      "                                           'the value of $\\\\lambda _{\\\\rm '\n",
      "                                           'CA}$.',\n",
      "                                           'Some examples of model outputs are '\n",
      "                                           'shown in Table TABREF26. The first '\n",
      "                                           'two examples suggest that our '\n",
      "                                           'model successfully learned '\n",
      "                                           'negation without explicit '\n",
      "                                           'supervision. Similarly, the next '\n",
      "                                           'two examples differ only in voice '\n",
      "                                           'but the model correctly recognized '\n",
      "                                           'that they had opposite polarities. '\n",
      "                                           'The last two examples share the '\n",
      "                                           'predicate “落とす\" (drop) and only '\n",
      "                                           'the objects are different. The '\n",
      "                                           'second event “肩を落とす\" (lit. drop '\n",
      "                                           \"one's shoulders) is an idiom that \"\n",
      "                                           'expresses a disappointed feeling. '\n",
      "                                           'The examples demonstrate that our '\n",
      "                                           'model correctly learned '\n",
      "                                           'non-compositional expressions.',\n",
      "                                           ''],\n",
      "                                       [   'In this paper, we proposed to use '\n",
      "                                           'discourse relations to effectively '\n",
      "                                           'propagate polarities of affective '\n",
      "                                           'events from seeds. Experiments '\n",
      "                                           'show that, even with a minimal '\n",
      "                                           'amount of supervision, the '\n",
      "                                           'proposed method performed well.',\n",
      "                                           'Although event pairs linked by '\n",
      "                                           'discourse analysis are shown to be '\n",
      "                                           'useful, they nevertheless contain '\n",
      "                                           'noises. Adding '\n",
      "                                           'linguistically-motivated filtering '\n",
      "                                           'rules would help improve the '\n",
      "                                           'performance.'],\n",
      "                                       [   'We thank Nobuhiro Kaji for '\n",
      "                                           'providing the ACP Corpus and '\n",
      "                                           'Hirokazu Kiyomaru and Yudai '\n",
      "                                           'Kishimoto for their help in '\n",
      "                                           'extracting event pairs. This work '\n",
      "                                           'was partially supported by Yahoo! '\n",
      "                                           'Japan Corporation.'],\n",
      "                                       [   '喜ぶ (rejoice), 嬉しい (be glad), 楽しい '\n",
      "                                           '(be pleasant), 幸せ (be happy), 感動 '\n",
      "                                           '(be impressed), 興奮 (be excited), '\n",
      "                                           '懐かしい (feel nostalgic), 好き (like), '\n",
      "                                           '尊敬 (respect), 安心 (be relieved), 感心 '\n",
      "                                           '(admire), 落ち着く (be calm), 満足 (be '\n",
      "                                           'satisfied), 癒される (be healed), and '\n",
      "                                           'スッキリ (be refreshed).'],\n",
      "                                       [   '怒る (get angry), 悲しい (be sad), 寂しい '\n",
      "                                           '(be lonely), 怖い (be scared), 不安 '\n",
      "                                           '(feel anxious), 恥ずかしい (be '\n",
      "                                           'embarrassed), 嫌 (hate), 落ち込む (feel '\n",
      "                                           'down), 退屈 (be bored), 絶望 (feel '\n",
      "                                           'hopeless), 辛い (have a hard time), '\n",
      "                                           '困る (have trouble), 憂鬱 (be '\n",
      "                                           'depressed), 心配 (be worried), and '\n",
      "                                           '情けない (be sorry).'],\n",
      "                                       [   'The dimension of the embedding '\n",
      "                                           'layer was 256. The embedding layer '\n",
      "                                           'was initialized with the word '\n",
      "                                           'embeddings pretrained using the '\n",
      "                                           'Web corpus. The input sentences '\n",
      "                                           'were segmented into words by the '\n",
      "                                           'morphological analyzer Juman++. '\n",
      "                                           'The vocabulary size was 100,000. '\n",
      "                                           'The number of hidden layers was 2. '\n",
      "                                           'The dimension of hidden units was '\n",
      "                                           '256. The optimizer was Momentum '\n",
      "                                           'SGD BIBREF21. The mini-batch size '\n",
      "                                           'was 1024. We ran 100 epochs and '\n",
      "                                           'selected the snapshot that '\n",
      "                                           'achieved the highest score for the '\n",
      "                                           'dev set.'],\n",
      "                                       [   'We used a Japanese BERT model '\n",
      "                                           'pretrained with Japanese '\n",
      "                                           'Wikipedia. The input sentences '\n",
      "                                           'were segmented into words by '\n",
      "                                           'Juman++, and words were broken '\n",
      "                                           'into subwords by applying BPE '\n",
      "                                           'BIBREF20. The vocabulary size was '\n",
      "                                           '32,000. The maximum length of an '\n",
      "                                           'input sequence was 128. The number '\n",
      "                                           'of hidden layers was 12. The '\n",
      "                                           'dimension of hidden units was 768. '\n",
      "                                           'The number of self-attention heads '\n",
      "                                           'was 12. The optimizer was Adam '\n",
      "                                           'BIBREF19. The mini-batch size was '\n",
      "                                           '32. We ran 1 epoch.']],\n",
      "                     'section_name': [   'Introduction',\n",
      "                                         'Related Work',\n",
      "                                         'Proposed Method',\n",
      "                                         'Proposed Method ::: Polarity '\n",
      "                                         'Function',\n",
      "                                         'Proposed Method ::: Discourse '\n",
      "                                         'Relation-Based Event Pairs',\n",
      "                                         'Proposed Method ::: Discourse '\n",
      "                                         'Relation-Based Event Pairs ::: AL '\n",
      "                                         '(Automatically Labeled Pairs)',\n",
      "                                         'Proposed Method ::: Discourse '\n",
      "                                         'Relation-Based Event Pairs ::: CA '\n",
      "                                         '(Cause Pairs)',\n",
      "                                         'Proposed Method ::: Discourse '\n",
      "                                         'Relation-Based Event Pairs ::: CO '\n",
      "                                         '(Concession Pairs)',\n",
      "                                         'Proposed Method ::: Loss Functions',\n",
      "                                         'Experiments',\n",
      "                                         'Experiments ::: Dataset',\n",
      "                                         'Experiments ::: Dataset ::: AL, CA, '\n",
      "                                         'and CO',\n",
      "                                         'Experiments ::: Dataset ::: ACP (ACP '\n",
      "                                         'Corpus)',\n",
      "                                         'Experiments ::: Model Configurations',\n",
      "                                         'Experiments ::: Results and '\n",
      "                                         'Discussion',\n",
      "                                         'Conclusion',\n",
      "                                         'Acknowledgments',\n",
      "                                         'Appendices ::: Seed Lexicon ::: '\n",
      "                                         'Positive Words',\n",
      "                                         'Appendices ::: Seed Lexicon ::: '\n",
      "                                         'Negative Words',\n",
      "                                         'Appendices ::: Settings of Encoder '\n",
      "                                         '::: BiGRU',\n",
      "                                         'Appendices ::: Settings of Encoder '\n",
      "                                         '::: BERT']},\n",
      "    'id': '1909.00694',\n",
      "    'qas': {   'answers': [   {   'annotation_id': [   '31e85022a847f37c15fd0415f3c450c74c8e4755',\n",
      "                                                       '95da0a6e1b08db74a405c6a71067c9b272a50ff5'],\n",
      "                                  'answer': [   {   'evidence': [   'The seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'consists '\n",
      "                                                                    'of '\n",
      "                                                                    'positive '\n",
      "                                                                    'and '\n",
      "                                                                    'negative '\n",
      "                                                                    'predicates. '\n",
      "                                                                    'If the '\n",
      "                                                                    'predicate '\n",
      "                                                                    'of an '\n",
      "                                                                    'extracted '\n",
      "                                                                    'event is '\n",
      "                                                                    'in the '\n",
      "                                                                    'seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'and does '\n",
      "                                                                    'not '\n",
      "                                                                    'involve '\n",
      "                                                                    'complex '\n",
      "                                                                    'phenomena '\n",
      "                                                                    'like '\n",
      "                                                                    'negation, '\n",
      "                                                                    'we assign '\n",
      "                                                                    'the '\n",
      "                                                                    'corresponding '\n",
      "                                                                    'polarity '\n",
      "                                                                    'score '\n",
      "                                                                    '($+1$ for '\n",
      "                                                                    'positive '\n",
      "                                                                    'events '\n",
      "                                                                    'and $-1$ '\n",
      "                                                                    'for '\n",
      "                                                                    'negative '\n",
      "                                                                    'events) '\n",
      "                                                                    'to the '\n",
      "                                                                    'event. We '\n",
      "                                                                    'expect '\n",
      "                                                                    'the model '\n",
      "                                                                    'to '\n",
      "                                                                    'automatically '\n",
      "                                                                    'learn '\n",
      "                                                                    'complex '\n",
      "                                                                    'phenomena '\n",
      "                                                                    'through '\n",
      "                                                                    'label '\n",
      "                                                                    'propagation. '\n",
      "                                                                    'Based on '\n",
      "                                                                    'the '\n",
      "                                                                    'availability '\n",
      "                                                                    'of scores '\n",
      "                                                                    'and the '\n",
      "                                                                    'types of '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relations, '\n",
      "                                                                    'we '\n",
      "                                                                    'classify '\n",
      "                                                                    'the '\n",
      "                                                                    'extracted '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs '\n",
      "                                                                    'into the '\n",
      "                                                                    'following '\n",
      "                                                                    'three '\n",
      "                                                                    'types.'],\n",
      "                                                    'extractive_spans': [],\n",
      "                                                    'free_form_answer': 'a '\n",
      "                                                                        'vocabulary '\n",
      "                                                                        'of '\n",
      "                                                                        'positive '\n",
      "                                                                        'and '\n",
      "                                                                        'negative '\n",
      "                                                                        'predicates '\n",
      "                                                                        'that '\n",
      "                                                                        'helps '\n",
      "                                                                        'determine '\n",
      "                                                                        'the '\n",
      "                                                                        'polarity '\n",
      "                                                                        'score '\n",
      "                                                                        'of an '\n",
      "                                                                        'event',\n",
      "                                                    'highlighted_evidence': [   'The '\n",
      "                                                                                'seed '\n",
      "                                                                                'lexicon '\n",
      "                                                                                'consists '\n",
      "                                                                                'of '\n",
      "                                                                                'positive '\n",
      "                                                                                'and '\n",
      "                                                                                'negative '\n",
      "                                                                                'predicates. '\n",
      "                                                                                'If '\n",
      "                                                                                'the '\n",
      "                                                                                'predicate '\n",
      "                                                                                'of '\n",
      "                                                                                'an '\n",
      "                                                                                'extracted '\n",
      "                                                                                'event '\n",
      "                                                                                'is '\n",
      "                                                                                'in '\n",
      "                                                                                'the '\n",
      "                                                                                'seed '\n",
      "                                                                                'lexicon '\n",
      "                                                                                'and '\n",
      "                                                                                'does '\n",
      "                                                                                'not '\n",
      "                                                                                'involve '\n",
      "                                                                                'complex '\n",
      "                                                                                'phenomena '\n",
      "                                                                                'like '\n",
      "                                                                                'negation, '\n",
      "                                                                                'we '\n",
      "                                                                                'assign '\n",
      "                                                                                'the '\n",
      "                                                                                'corresponding '\n",
      "                                                                                'polarity '\n",
      "                                                                                'score '\n",
      "                                                                                '($+1$ '\n",
      "                                                                                'for '\n",
      "                                                                                'positive '\n",
      "                                                                                'events '\n",
      "                                                                                'and '\n",
      "                                                                                '$-1$ '\n",
      "                                                                                'for '\n",
      "                                                                                'negative '\n",
      "                                                                                'events) '\n",
      "                                                                                'to '\n",
      "                                                                                'the '\n",
      "                                                                                'event.',\n",
      "                                                                                'It '\n",
      "                                                                                'is '\n",
      "                                                                                'a '],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None},\n",
      "                                                {   'evidence': [   'The seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'consists '\n",
      "                                                                    'of '\n",
      "                                                                    'positive '\n",
      "                                                                    'and '\n",
      "                                                                    'negative '\n",
      "                                                                    'predicates. '\n",
      "                                                                    'If the '\n",
      "                                                                    'predicate '\n",
      "                                                                    'of an '\n",
      "                                                                    'extracted '\n",
      "                                                                    'event is '\n",
      "                                                                    'in the '\n",
      "                                                                    'seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'and does '\n",
      "                                                                    'not '\n",
      "                                                                    'involve '\n",
      "                                                                    'complex '\n",
      "                                                                    'phenomena '\n",
      "                                                                    'like '\n",
      "                                                                    'negation, '\n",
      "                                                                    'we assign '\n",
      "                                                                    'the '\n",
      "                                                                    'corresponding '\n",
      "                                                                    'polarity '\n",
      "                                                                    'score '\n",
      "                                                                    '($+1$ for '\n",
      "                                                                    'positive '\n",
      "                                                                    'events '\n",
      "                                                                    'and $-1$ '\n",
      "                                                                    'for '\n",
      "                                                                    'negative '\n",
      "                                                                    'events) '\n",
      "                                                                    'to the '\n",
      "                                                                    'event. We '\n",
      "                                                                    'expect '\n",
      "                                                                    'the model '\n",
      "                                                                    'to '\n",
      "                                                                    'automatically '\n",
      "                                                                    'learn '\n",
      "                                                                    'complex '\n",
      "                                                                    'phenomena '\n",
      "                                                                    'through '\n",
      "                                                                    'label '\n",
      "                                                                    'propagation. '\n",
      "                                                                    'Based on '\n",
      "                                                                    'the '\n",
      "                                                                    'availability '\n",
      "                                                                    'of scores '\n",
      "                                                                    'and the '\n",
      "                                                                    'types of '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relations, '\n",
      "                                                                    'we '\n",
      "                                                                    'classify '\n",
      "                                                                    'the '\n",
      "                                                                    'extracted '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs '\n",
      "                                                                    'into the '\n",
      "                                                                    'following '\n",
      "                                                                    'three '\n",
      "                                                                    'types.'],\n",
      "                                                    'extractive_spans': [   'seed '\n",
      "                                                                            'lexicon '\n",
      "                                                                            'consists '\n",
      "                                                                            'of '\n",
      "                                                                            'positive '\n",
      "                                                                            'and '\n",
      "                                                                            'negative '\n",
      "                                                                            'predicates'],\n",
      "                                                    'free_form_answer': '',\n",
      "                                                    'highlighted_evidence': [   'The '\n",
      "                                                                                'seed '\n",
      "                                                                                'lexicon '\n",
      "                                                                                'consists '\n",
      "                                                                                'of '\n",
      "                                                                                'positive '\n",
      "                                                                                'and '\n",
      "                                                                                'negative '\n",
      "                                                                                'predicates. '\n",
      "                                                                                'If '\n",
      "                                                                                'the '\n",
      "                                                                                'predicate '\n",
      "                                                                                'of '\n",
      "                                                                                'an '\n",
      "                                                                                'extracted '\n",
      "                                                                                'event '\n",
      "                                                                                'is '\n",
      "                                                                                'in '\n",
      "                                                                                'the '\n",
      "                                                                                'seed '\n",
      "                                                                                'lexicon '\n",
      "                                                                                'and '\n",
      "                                                                                'does '\n",
      "                                                                                'not '\n",
      "                                                                                'involve '\n",
      "                                                                                'complex '\n",
      "                                                                                'phenomena '\n",
      "                                                                                'like '\n",
      "                                                                                'negation, '\n",
      "                                                                                'we '\n",
      "                                                                                'assign '\n",
      "                                                                                'the '\n",
      "                                                                                'corresponding '\n",
      "                                                                                'polarity '\n",
      "                                                                                'score '\n",
      "                                                                                '($+1$ '\n",
      "                                                                                'for '\n",
      "                                                                                'positive '\n",
      "                                                                                'events '\n",
      "                                                                                'and '\n",
      "                                                                                '$-1$ '\n",
      "                                                                                'for '\n",
      "                                                                                'negative '\n",
      "                                                                                'events) '\n",
      "                                                                                'to '\n",
      "                                                                                'the '\n",
      "                                                                                'event.'],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None}],\n",
      "                                  'worker_id': [   'c1fbdd7a261021041f75fbe00a55b4c386ebbbb4',\n",
      "                                                   '2cfd959e433f290bb50b55722370f0d22fe090b7']},\n",
      "                              {   'annotation_id': [   '1e5e867244ea656c4b7632628086209cf9bae5fa'],\n",
      "                                  'answer': [   {   'evidence': [   'FLOAT '\n",
      "                                                                    'SELECTED: '\n",
      "                                                                    'Table 3: '\n",
      "                                                                    'Performance '\n",
      "                                                                    'of '\n",
      "                                                                    'various '\n",
      "                                                                    'models on '\n",
      "                                                                    'the ACP '\n",
      "                                                                    'test set.',\n",
      "                                                                    'FLOAT '\n",
      "                                                                    'SELECTED: '\n",
      "                                                                    'Table 4: '\n",
      "                                                                    'Results '\n",
      "                                                                    'for small '\n",
      "                                                                    'labeled '\n",
      "                                                                    'training '\n",
      "                                                                    'data. '\n",
      "                                                                    'Given the '\n",
      "                                                                    'performance '\n",
      "                                                                    'with the '\n",
      "                                                                    'full '\n",
      "                                                                    'dataset, '\n",
      "                                                                    'we show '\n",
      "                                                                    'BERT '\n",
      "                                                                    'trained '\n",
      "                                                                    'only with '\n",
      "                                                                    'the AL '\n",
      "                                                                    'data.',\n",
      "                                                                    'As for '\n",
      "                                                                    '${\\\\rm '\n",
      "                                                                    'Encoder}$, '\n",
      "                                                                    'we '\n",
      "                                                                    'compared '\n",
      "                                                                    'two types '\n",
      "                                                                    'of neural '\n",
      "                                                                    'networks: '\n",
      "                                                                    'BiGRU and '\n",
      "                                                                    'BERT. GRU '\n",
      "                                                                    'BIBREF16 '\n",
      "                                                                    'is a '\n",
      "                                                                    'recurrent '\n",
      "                                                                    'neural '\n",
      "                                                                    'network '\n",
      "                                                                    'sequence '\n",
      "                                                                    'encoder. '\n",
      "                                                                    'BiGRU '\n",
      "                                                                    'reads an '\n",
      "                                                                    'input '\n",
      "                                                                    'sequence '\n",
      "                                                                    'forward '\n",
      "                                                                    'and '\n",
      "                                                                    'backward '\n",
      "                                                                    'and the '\n",
      "                                                                    'output is '\n",
      "                                                                    'the '\n",
      "                                                                    'concatenation '\n",
      "                                                                    'of the '\n",
      "                                                                    'final '\n",
      "                                                                    'forward '\n",
      "                                                                    'and '\n",
      "                                                                    'backward '\n",
      "                                                                    'hidden '\n",
      "                                                                    'states.',\n",
      "                                                                    'We '\n",
      "                                                                    'trained '\n",
      "                                                                    'the model '\n",
      "                                                                    'with the '\n",
      "                                                                    'following '\n",
      "                                                                    'four '\n",
      "                                                                    'combinations '\n",
      "                                                                    'of the '\n",
      "                                                                    'datasets: '\n",
      "                                                                    'AL, '\n",
      "                                                                    'AL+CA+CO '\n",
      "                                                                    '(two '\n",
      "                                                                    'proposed '\n",
      "                                                                    'models), '\n",
      "                                                                    'ACP '\n",
      "                                                                    '(supervised), '\n",
      "                                                                    'and '\n",
      "                                                                    'ACP+AL+CA+CO '\n",
      "                                                                    '(semi-supervised). '\n",
      "                                                                    'The '\n",
      "                                                                    'corresponding '\n",
      "                                                                    'objective '\n",
      "                                                                    'functions '\n",
      "                                                                    'were: '\n",
      "                                                                    '$\\\\mathcal '\n",
      "                                                                    '{L}_{\\\\rm '\n",
      "                                                                    'AL}$, '\n",
      "                                                                    '$\\\\mathcal '\n",
      "                                                                    '{L}_{\\\\rm '\n",
      "                                                                    'AL} + '\n",
      "                                                                    '\\\\mathcal '\n",
      "                                                                    '{L}_{\\\\rm '\n",
      "                                                                    'CA} + '\n",
      "                                                                    '\\\\mathcal '\n",
      "                                                                    '{L}_{\\\\rm '\n",
      "                                                                    'CO}$, '\n",
      "                                                                    '$\\\\mathcal '\n",
      "                                                                    '{L}_{\\\\rm '\n",
      "                                                                    'ACP}$, '\n",
      "                                                                    'and '\n",
      "                                                                    '$\\\\mathcal '\n",
      "                                                                    '{L}_{\\\\rm '\n",
      "                                                                    'ACP} + '\n",
      "                                                                    '\\\\mathcal '\n",
      "                                                                    '{L}_{\\\\rm '\n",
      "                                                                    'AL} + '\n",
      "                                                                    '\\\\mathcal '\n",
      "                                                                    '{L}_{\\\\rm '\n",
      "                                                                    'CA} + '\n",
      "                                                                    '\\\\mathcal '\n",
      "                                                                    '{L}_{\\\\rm '\n",
      "                                                                    'CO}$.'],\n",
      "                                                    'extractive_spans': [],\n",
      "                                                    'free_form_answer': 'Using '\n",
      "                                                                        'all '\n",
      "                                                                        'data '\n",
      "                                                                        'to '\n",
      "                                                                        'train: '\n",
      "                                                                        'AL -- '\n",
      "                                                                        'BiGRU '\n",
      "                                                                        'achieved '\n",
      "                                                                        '0.843 '\n",
      "                                                                        'accuracy, '\n",
      "                                                                        'AL -- '\n",
      "                                                                        'BERT '\n",
      "                                                                        'achieved '\n",
      "                                                                        '0.863 '\n",
      "                                                                        'accuracy, '\n",
      "                                                                        'AL+CA+CO '\n",
      "                                                                        '-- '\n",
      "                                                                        'BiGRU '\n",
      "                                                                        'achieved '\n",
      "                                                                        '0.866 '\n",
      "                                                                        'accuracy, '\n",
      "                                                                        'AL+CA+CO '\n",
      "                                                                        '-- '\n",
      "                                                                        'BERT '\n",
      "                                                                        'achieved '\n",
      "                                                                        '0.835, '\n",
      "                                                                        'accuracy, '\n",
      "                                                                        'ACP '\n",
      "                                                                        '-- '\n",
      "                                                                        'BiGRU '\n",
      "                                                                        'achieved '\n",
      "                                                                        '0.919 '\n",
      "                                                                        'accuracy, '\n",
      "                                                                        'ACP '\n",
      "                                                                        '-- '\n",
      "                                                                        'BERT '\n",
      "                                                                        'achived '\n",
      "                                                                        '0.933, '\n",
      "                                                                        'accuracy, '\n",
      "                                                                        'ACP+AL+CA+CO '\n",
      "                                                                        '-- '\n",
      "                                                                        'BiGRU '\n",
      "                                                                        'achieved '\n",
      "                                                                        '0.917 '\n",
      "                                                                        'accuracy, '\n",
      "                                                                        'ACP+AL+CA+CO '\n",
      "                                                                        '-- '\n",
      "                                                                        'BERT '\n",
      "                                                                        'achieved '\n",
      "                                                                        '0.913 '\n",
      "                                                                        'accuracy. \\n'\n",
      "                                                                        'Using '\n",
      "                                                                        'a '\n",
      "                                                                        'subset '\n",
      "                                                                        'to '\n",
      "                                                                        'train: '\n",
      "                                                                        'BERT '\n",
      "                                                                        'achieved '\n",
      "                                                                        '0.876 '\n",
      "                                                                        'accuracy '\n",
      "                                                                        'using '\n",
      "                                                                        'ACP '\n",
      "                                                                        '(6K), '\n",
      "                                                                        'BERT '\n",
      "                                                                        'achieved '\n",
      "                                                                        '0.886 '\n",
      "                                                                        'accuracy '\n",
      "                                                                        'using '\n",
      "                                                                        'ACP '\n",
      "                                                                        '(6K) '\n",
      "                                                                        '+ AL, '\n",
      "                                                                        'BiGRU '\n",
      "                                                                        'achieved '\n",
      "                                                                        '0.830 '\n",
      "                                                                        'accuracy '\n",
      "                                                                        'using '\n",
      "                                                                        'ACP '\n",
      "                                                                        '(6K), '\n",
      "                                                                        'BiGRU '\n",
      "                                                                        'achieved '\n",
      "                                                                        '0.879 '\n",
      "                                                                        'accuracy '\n",
      "                                                                        'using '\n",
      "                                                                        'ACP '\n",
      "                                                                        '(6K) '\n",
      "                                                                        '+ AL '\n",
      "                                                                        '+ CA '\n",
      "                                                                        '+ CO.',\n",
      "                                                    'highlighted_evidence': [   'FLOAT '\n",
      "                                                                                'SELECTED: '\n",
      "                                                                                'Table '\n",
      "                                                                                '3: '\n",
      "                                                                                'Performance '\n",
      "                                                                                'of '\n",
      "                                                                                'various '\n",
      "                                                                                'models '\n",
      "                                                                                'on '\n",
      "                                                                                'the '\n",
      "                                                                                'ACP '\n",
      "                                                                                'test '\n",
      "                                                                                'set.',\n",
      "                                                                                'FLOAT '\n",
      "                                                                                'SELECTED: '\n",
      "                                                                                'Table '\n",
      "                                                                                '4: '\n",
      "                                                                                'Results '\n",
      "                                                                                'for '\n",
      "                                                                                'small '\n",
      "                                                                                'labeled '\n",
      "                                                                                'training '\n",
      "                                                                                'data. '\n",
      "                                                                                'Given '\n",
      "                                                                                'the '\n",
      "                                                                                'performance '\n",
      "                                                                                'with '\n",
      "                                                                                'the '\n",
      "                                                                                'full '\n",
      "                                                                                'dataset, '\n",
      "                                                                                'we '\n",
      "                                                                                'show '\n",
      "                                                                                'BERT '\n",
      "                                                                                'trained '\n",
      "                                                                                'only '\n",
      "                                                                                'with '\n",
      "                                                                                'the '\n",
      "                                                                                'AL '\n",
      "                                                                                'data.',\n",
      "                                                                                'As '\n",
      "                                                                                'for '\n",
      "                                                                                '${\\\\rm '\n",
      "                                                                                'Encoder}$, '\n",
      "                                                                                'we '\n",
      "                                                                                'compared '\n",
      "                                                                                'two '\n",
      "                                                                                'types '\n",
      "                                                                                'of '\n",
      "                                                                                'neural '\n",
      "                                                                                'networks: '\n",
      "                                                                                'BiGRU '\n",
      "                                                                                'and '\n",
      "                                                                                'BERT. ',\n",
      "                                                                                'We '\n",
      "                                                                                'trained '\n",
      "                                                                                'the '\n",
      "                                                                                'model '\n",
      "                                                                                'with '\n",
      "                                                                                'the '\n",
      "                                                                                'following '\n",
      "                                                                                'four '\n",
      "                                                                                'combinations '\n",
      "                                                                                'of '\n",
      "                                                                                'the '\n",
      "                                                                                'datasets: '\n",
      "                                                                                'AL, '\n",
      "                                                                                'AL+CA+CO '\n",
      "                                                                                '(two '\n",
      "                                                                                'proposed '\n",
      "                                                                                'models), '\n",
      "                                                                                'ACP '\n",
      "                                                                                '(supervised), '\n",
      "                                                                                'and '\n",
      "                                                                                'ACP+AL+CA+CO '\n",
      "                                                                                '(semi-supervised). '\n",
      "                                                                                'The '\n",
      "                                                                                'corresponding '\n",
      "                                                                                'objective '\n",
      "                                                                                'functions '\n",
      "                                                                                'were: '\n",
      "                                                                                '$\\\\mathcal '\n",
      "                                                                                '{L}_{\\\\rm '\n",
      "                                                                                'AL}$, '\n",
      "                                                                                '$\\\\mathcal '\n",
      "                                                                                '{L}_{\\\\rm '\n",
      "                                                                                'AL} '\n",
      "                                                                                '+ '\n",
      "                                                                                '\\\\mathcal '\n",
      "                                                                                '{L}_{\\\\rm '\n",
      "                                                                                'CA} '\n",
      "                                                                                '+ '\n",
      "                                                                                '\\\\mathcal '\n",
      "                                                                                '{L}_{\\\\rm '\n",
      "                                                                                'CO}$, '\n",
      "                                                                                '$\\\\mathcal '\n",
      "                                                                                '{L}_{\\\\rm '\n",
      "                                                                                'ACP}$, '\n",
      "                                                                                'and '\n",
      "                                                                                '$\\\\mathcal '\n",
      "                                                                                '{L}_{\\\\rm '\n",
      "                                                                                'ACP} '\n",
      "                                                                                '+ '\n",
      "                                                                                '\\\\mathcal '\n",
      "                                                                                '{L}_{\\\\rm '\n",
      "                                                                                'AL} '\n",
      "                                                                                '+ '\n",
      "                                                                                '\\\\mathcal '\n",
      "                                                                                '{L}_{\\\\rm '\n",
      "                                                                                'CA} '\n",
      "                                                                                '+ '\n",
      "                                                                                '\\\\mathcal '\n",
      "                                                                                '{L}_{\\\\rm '\n",
      "                                                                                'CO}$.'],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None}],\n",
      "                                  'worker_id': [   '2cfd959e433f290bb50b55722370f0d22fe090b7']},\n",
      "                              {   'annotation_id': [   '49a78a07d2eed545556a835ccf2eb40e5eee9801',\n",
      "                                                       'acd6d15bd67f4b1496ee8af1c93c33e7d59c89e1'],\n",
      "                                  'answer': [   {   'evidence': [   'In this '\n",
      "                                                                    'paper, we '\n",
      "                                                                    'propose a '\n",
      "                                                                    'simple '\n",
      "                                                                    'and '\n",
      "                                                                    'effective '\n",
      "                                                                    'method '\n",
      "                                                                    'for '\n",
      "                                                                    'learning '\n",
      "                                                                    'affective '\n",
      "                                                                    'events '\n",
      "                                                                    'that only '\n",
      "                                                                    'requires '\n",
      "                                                                    'a very '\n",
      "                                                                    'small '\n",
      "                                                                    'seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'and a '\n",
      "                                                                    'large raw '\n",
      "                                                                    'corpus. '\n",
      "                                                                    'As '\n",
      "                                                                    'illustrated '\n",
      "                                                                    'in Figure '\n",
      "                                                                    'FIGREF1, '\n",
      "                                                                    'our key '\n",
      "                                                                    'idea is '\n",
      "                                                                    'that we '\n",
      "                                                                    'can '\n",
      "                                                                    'exploit '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relations '\n",
      "                                                                    'BIBREF4 '\n",
      "                                                                    'to '\n",
      "                                                                    'efficiently '\n",
      "                                                                    'propagate '\n",
      "                                                                    'polarity '\n",
      "                                                                    'from seed '\n",
      "                                                                    'predicates '\n",
      "                                                                    'that '\n",
      "                                                                    'directly '\n",
      "                                                                    'report '\n",
      "                                                                    \"one's \"\n",
      "                                                                    'emotions '\n",
      "                                                                    '(e.g., '\n",
      "                                                                    '“to be '\n",
      "                                                                    'glad” is '\n",
      "                                                                    'positive). '\n",
      "                                                                    'Suppose '\n",
      "                                                                    'that '\n",
      "                                                                    'events '\n",
      "                                                                    '$x_1$ are '\n",
      "                                                                    '$x_2$ are '\n",
      "                                                                    'in the '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relation '\n",
      "                                                                    'of Cause '\n",
      "                                                                    '(i.e., '\n",
      "                                                                    '$x_1$ '\n",
      "                                                                    'causes '\n",
      "                                                                    '$x_2$). '\n",
      "                                                                    'If the '\n",
      "                                                                    'seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'suggests '\n",
      "                                                                    '$x_2$ is '\n",
      "                                                                    'positive, '\n",
      "                                                                    '$x_1$ is '\n",
      "                                                                    'also '\n",
      "                                                                    'likely to '\n",
      "                                                                    'be '\n",
      "                                                                    'positive '\n",
      "                                                                    'because '\n",
      "                                                                    'it '\n",
      "                                                                    'triggers '\n",
      "                                                                    'the '\n",
      "                                                                    'positive '\n",
      "                                                                    'emotion. '\n",
      "                                                                    'The fact '\n",
      "                                                                    'that '\n",
      "                                                                    '$x_2$ is '\n",
      "                                                                    'known to '\n",
      "                                                                    'be '\n",
      "                                                                    'negative '\n",
      "                                                                    'indicates '\n",
      "                                                                    'the '\n",
      "                                                                    'negative '\n",
      "                                                                    'polarity '\n",
      "                                                                    'of $x_1$. '\n",
      "                                                                    'Similarly, '\n",
      "                                                                    'if $x_1$ '\n",
      "                                                                    'and $x_2$ '\n",
      "                                                                    'are in '\n",
      "                                                                    'the '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relation '\n",
      "                                                                    'of '\n",
      "                                                                    'Concession '\n",
      "                                                                    '(i.e., '\n",
      "                                                                    '$x_2$ in '\n",
      "                                                                    'spite of '\n",
      "                                                                    '$x_1$), '\n",
      "                                                                    'the '\n",
      "                                                                    'reverse '\n",
      "                                                                    'of '\n",
      "                                                                    \"$x_2$'s \"\n",
      "                                                                    'polarity '\n",
      "                                                                    'can be '\n",
      "                                                                    'propagated '\n",
      "                                                                    'to $x_1$. '\n",
      "                                                                    'Even if '\n",
      "                                                                    \"$x_2$'s \"\n",
      "                                                                    'polarity '\n",
      "                                                                    'is not '\n",
      "                                                                    'known in '\n",
      "                                                                    'advance, '\n",
      "                                                                    'we can '\n",
      "                                                                    'exploit '\n",
      "                                                                    'the '\n",
      "                                                                    'tendency '\n",
      "                                                                    'of $x_1$ '\n",
      "                                                                    'and $x_2$ '\n",
      "                                                                    'to be of '\n",
      "                                                                    'the same '\n",
      "                                                                    'polarity '\n",
      "                                                                    '(for '\n",
      "                                                                    'Cause) or '\n",
      "                                                                    'of the '\n",
      "                                                                    'reverse '\n",
      "                                                                    'polarity '\n",
      "                                                                    '(for '\n",
      "                                                                    'Concession) '\n",
      "                                                                    'although '\n",
      "                                                                    'the '\n",
      "                                                                    'heuristic '\n",
      "                                                                    'is not '\n",
      "                                                                    'exempt '\n",
      "                                                                    'from '\n",
      "                                                                    'counterexamples. '\n",
      "                                                                    'We '\n",
      "                                                                    'transform '\n",
      "                                                                    'this idea '\n",
      "                                                                    'into '\n",
      "                                                                    'objective '\n",
      "                                                                    'functions '\n",
      "                                                                    'and train '\n",
      "                                                                    'neural '\n",
      "                                                                    'network '\n",
      "                                                                    'models '\n",
      "                                                                    'that '\n",
      "                                                                    'predict '\n",
      "                                                                    'the '\n",
      "                                                                    'polarity '\n",
      "                                                                    'of a '\n",
      "                                                                    'given '\n",
      "                                                                    'event.'],\n",
      "                                                    'extractive_spans': [],\n",
      "                                                    'free_form_answer': 'based '\n",
      "                                                                        'on '\n",
      "                                                                        'the '\n",
      "                                                                        'relation '\n",
      "                                                                        'between '\n",
      "                                                                        'events, '\n",
      "                                                                        'the '\n",
      "                                                                        'suggested '\n",
      "                                                                        'polarity '\n",
      "                                                                        'of '\n",
      "                                                                        'one '\n",
      "                                                                        'event '\n",
      "                                                                        'can '\n",
      "                                                                        'determine '\n",
      "                                                                        'the '\n",
      "                                                                        'possible '\n",
      "                                                                        'polarity '\n",
      "                                                                        'of '\n",
      "                                                                        'the '\n",
      "                                                                        'other '\n",
      "                                                                        'event ',\n",
      "                                                    'highlighted_evidence': [   'As '\n",
      "                                                                                'illustrated '\n",
      "                                                                                'in '\n",
      "                                                                                'Figure '\n",
      "                                                                                'FIGREF1, '\n",
      "                                                                                'our '\n",
      "                                                                                'key '\n",
      "                                                                                'idea '\n",
      "                                                                                'is '\n",
      "                                                                                'that '\n",
      "                                                                                'we '\n",
      "                                                                                'can '\n",
      "                                                                                'exploit '\n",
      "                                                                                'discourse '\n",
      "                                                                                'relations '\n",
      "                                                                                'BIBREF4 '\n",
      "                                                                                'to '\n",
      "                                                                                'efficiently '\n",
      "                                                                                'propagate '\n",
      "                                                                                'polarity '\n",
      "                                                                                'from '\n",
      "                                                                                'seed '\n",
      "                                                                                'predicates '\n",
      "                                                                                'that '\n",
      "                                                                                'directly '\n",
      "                                                                                'report '\n",
      "                                                                                \"one's \"\n",
      "                                                                                'emotions '\n",
      "                                                                                '(e.g., '\n",
      "                                                                                '“to '\n",
      "                                                                                'be '\n",
      "                                                                                'glad” '\n",
      "                                                                                'is '\n",
      "                                                                                'positive). '\n",
      "                                                                                'Suppose '\n",
      "                                                                                'that '\n",
      "                                                                                'events '\n",
      "                                                                                '$x_1$ '\n",
      "                                                                                'are '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'are '\n",
      "                                                                                'in '\n",
      "                                                                                'the '\n",
      "                                                                                'discourse '\n",
      "                                                                                'relation '\n",
      "                                                                                'of '\n",
      "                                                                                'Cause '\n",
      "                                                                                '(i.e., '\n",
      "                                                                                '$x_1$ '\n",
      "                                                                                'causes '\n",
      "                                                                                '$x_2$). '\n",
      "                                                                                'If '\n",
      "                                                                                'the '\n",
      "                                                                                'seed '\n",
      "                                                                                'lexicon '\n",
      "                                                                                'suggests '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'is '\n",
      "                                                                                'positive, '\n",
      "                                                                                '$x_1$ '\n",
      "                                                                                'is '\n",
      "                                                                                'also '\n",
      "                                                                                'likely '\n",
      "                                                                                'to '\n",
      "                                                                                'be '\n",
      "                                                                                'positive '\n",
      "                                                                                'because '\n",
      "                                                                                'it '\n",
      "                                                                                'triggers '\n",
      "                                                                                'the '\n",
      "                                                                                'positive '\n",
      "                                                                                'emotion. '\n",
      "                                                                                'The '\n",
      "                                                                                'fact '\n",
      "                                                                                'that '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'is '\n",
      "                                                                                'known '\n",
      "                                                                                'to '\n",
      "                                                                                'be '\n",
      "                                                                                'negative '\n",
      "                                                                                'indicates '\n",
      "                                                                                'the '\n",
      "                                                                                'negative '\n",
      "                                                                                'polarity '\n",
      "                                                                                'of '\n",
      "                                                                                '$x_1$. '\n",
      "                                                                                'Similarly, '\n",
      "                                                                                'if '\n",
      "                                                                                '$x_1$ '\n",
      "                                                                                'and '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'are '\n",
      "                                                                                'in '\n",
      "                                                                                'the '\n",
      "                                                                                'discourse '\n",
      "                                                                                'relation '\n",
      "                                                                                'of '\n",
      "                                                                                'Concession '\n",
      "                                                                                '(i.e., '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'in '\n",
      "                                                                                'spite '\n",
      "                                                                                'of '\n",
      "                                                                                '$x_1$), '\n",
      "                                                                                'the '\n",
      "                                                                                'reverse '\n",
      "                                                                                'of '\n",
      "                                                                                \"$x_2$'s \"\n",
      "                                                                                'polarity '\n",
      "                                                                                'can '\n",
      "                                                                                'be '\n",
      "                                                                                'propagated '\n",
      "                                                                                'to '\n",
      "                                                                                '$x_1$. '\n",
      "                                                                                'Even '\n",
      "                                                                                'if '\n",
      "                                                                                \"$x_2$'s \"\n",
      "                                                                                'polarity '\n",
      "                                                                                'is '\n",
      "                                                                                'not '\n",
      "                                                                                'known '\n",
      "                                                                                'in '\n",
      "                                                                                'advance, '\n",
      "                                                                                'we '\n",
      "                                                                                'can '\n",
      "                                                                                'exploit '\n",
      "                                                                                'the '\n",
      "                                                                                'tendency '\n",
      "                                                                                'of '\n",
      "                                                                                '$x_1$ '\n",
      "                                                                                'and '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'to '\n",
      "                                                                                'be '\n",
      "                                                                                'of '\n",
      "                                                                                'the '\n",
      "                                                                                'same '\n",
      "                                                                                'polarity '\n",
      "                                                                                '(for '\n",
      "                                                                                'Cause) '\n",
      "                                                                                'or '\n",
      "                                                                                'of '\n",
      "                                                                                'the '\n",
      "                                                                                'reverse '\n",
      "                                                                                'polarity '\n",
      "                                                                                '(for '\n",
      "                                                                                'Concession) '\n",
      "                                                                                'although '\n",
      "                                                                                'the '\n",
      "                                                                                'heuristic '\n",
      "                                                                                'is '\n",
      "                                                                                'not '\n",
      "                                                                                'exempt '\n",
      "                                                                                'from '\n",
      "                                                                                'counterexamples. '\n",
      "                                                                                'We '\n",
      "                                                                                'transform '\n",
      "                                                                                'this '\n",
      "                                                                                'idea '\n",
      "                                                                                'into '\n",
      "                                                                                'objective '\n",
      "                                                                                'functions '\n",
      "                                                                                'and '\n",
      "                                                                                'train '\n",
      "                                                                                'neural '\n",
      "                                                                                'network '\n",
      "                                                                                'models '\n",
      "                                                                                'that '\n",
      "                                                                                'predict '\n",
      "                                                                                'the '\n",
      "                                                                                'polarity '\n",
      "                                                                                'of '\n",
      "                                                                                'a '\n",
      "                                                                                'given '\n",
      "                                                                                'event.'],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None},\n",
      "                                                {   'evidence': [   'In this '\n",
      "                                                                    'paper, we '\n",
      "                                                                    'propose a '\n",
      "                                                                    'simple '\n",
      "                                                                    'and '\n",
      "                                                                    'effective '\n",
      "                                                                    'method '\n",
      "                                                                    'for '\n",
      "                                                                    'learning '\n",
      "                                                                    'affective '\n",
      "                                                                    'events '\n",
      "                                                                    'that only '\n",
      "                                                                    'requires '\n",
      "                                                                    'a very '\n",
      "                                                                    'small '\n",
      "                                                                    'seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'and a '\n",
      "                                                                    'large raw '\n",
      "                                                                    'corpus. '\n",
      "                                                                    'As '\n",
      "                                                                    'illustrated '\n",
      "                                                                    'in Figure '\n",
      "                                                                    'FIGREF1, '\n",
      "                                                                    'our key '\n",
      "                                                                    'idea is '\n",
      "                                                                    'that we '\n",
      "                                                                    'can '\n",
      "                                                                    'exploit '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relations '\n",
      "                                                                    'BIBREF4 '\n",
      "                                                                    'to '\n",
      "                                                                    'efficiently '\n",
      "                                                                    'propagate '\n",
      "                                                                    'polarity '\n",
      "                                                                    'from seed '\n",
      "                                                                    'predicates '\n",
      "                                                                    'that '\n",
      "                                                                    'directly '\n",
      "                                                                    'report '\n",
      "                                                                    \"one's \"\n",
      "                                                                    'emotions '\n",
      "                                                                    '(e.g., '\n",
      "                                                                    '“to be '\n",
      "                                                                    'glad” is '\n",
      "                                                                    'positive). '\n",
      "                                                                    'Suppose '\n",
      "                                                                    'that '\n",
      "                                                                    'events '\n",
      "                                                                    '$x_1$ are '\n",
      "                                                                    '$x_2$ are '\n",
      "                                                                    'in the '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relation '\n",
      "                                                                    'of Cause '\n",
      "                                                                    '(i.e., '\n",
      "                                                                    '$x_1$ '\n",
      "                                                                    'causes '\n",
      "                                                                    '$x_2$). '\n",
      "                                                                    'If the '\n",
      "                                                                    'seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'suggests '\n",
      "                                                                    '$x_2$ is '\n",
      "                                                                    'positive, '\n",
      "                                                                    '$x_1$ is '\n",
      "                                                                    'also '\n",
      "                                                                    'likely to '\n",
      "                                                                    'be '\n",
      "                                                                    'positive '\n",
      "                                                                    'because '\n",
      "                                                                    'it '\n",
      "                                                                    'triggers '\n",
      "                                                                    'the '\n",
      "                                                                    'positive '\n",
      "                                                                    'emotion. '\n",
      "                                                                    'The fact '\n",
      "                                                                    'that '\n",
      "                                                                    '$x_2$ is '\n",
      "                                                                    'known to '\n",
      "                                                                    'be '\n",
      "                                                                    'negative '\n",
      "                                                                    'indicates '\n",
      "                                                                    'the '\n",
      "                                                                    'negative '\n",
      "                                                                    'polarity '\n",
      "                                                                    'of $x_1$. '\n",
      "                                                                    'Similarly, '\n",
      "                                                                    'if $x_1$ '\n",
      "                                                                    'and $x_2$ '\n",
      "                                                                    'are in '\n",
      "                                                                    'the '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relation '\n",
      "                                                                    'of '\n",
      "                                                                    'Concession '\n",
      "                                                                    '(i.e., '\n",
      "                                                                    '$x_2$ in '\n",
      "                                                                    'spite of '\n",
      "                                                                    '$x_1$), '\n",
      "                                                                    'the '\n",
      "                                                                    'reverse '\n",
      "                                                                    'of '\n",
      "                                                                    \"$x_2$'s \"\n",
      "                                                                    'polarity '\n",
      "                                                                    'can be '\n",
      "                                                                    'propagated '\n",
      "                                                                    'to $x_1$. '\n",
      "                                                                    'Even if '\n",
      "                                                                    \"$x_2$'s \"\n",
      "                                                                    'polarity '\n",
      "                                                                    'is not '\n",
      "                                                                    'known in '\n",
      "                                                                    'advance, '\n",
      "                                                                    'we can '\n",
      "                                                                    'exploit '\n",
      "                                                                    'the '\n",
      "                                                                    'tendency '\n",
      "                                                                    'of $x_1$ '\n",
      "                                                                    'and $x_2$ '\n",
      "                                                                    'to be of '\n",
      "                                                                    'the same '\n",
      "                                                                    'polarity '\n",
      "                                                                    '(for '\n",
      "                                                                    'Cause) or '\n",
      "                                                                    'of the '\n",
      "                                                                    'reverse '\n",
      "                                                                    'polarity '\n",
      "                                                                    '(for '\n",
      "                                                                    'Concession) '\n",
      "                                                                    'although '\n",
      "                                                                    'the '\n",
      "                                                                    'heuristic '\n",
      "                                                                    'is not '\n",
      "                                                                    'exempt '\n",
      "                                                                    'from '\n",
      "                                                                    'counterexamples. '\n",
      "                                                                    'We '\n",
      "                                                                    'transform '\n",
      "                                                                    'this idea '\n",
      "                                                                    'into '\n",
      "                                                                    'objective '\n",
      "                                                                    'functions '\n",
      "                                                                    'and train '\n",
      "                                                                    'neural '\n",
      "                                                                    'network '\n",
      "                                                                    'models '\n",
      "                                                                    'that '\n",
      "                                                                    'predict '\n",
      "                                                                    'the '\n",
      "                                                                    'polarity '\n",
      "                                                                    'of a '\n",
      "                                                                    'given '\n",
      "                                                                    'event.',\n",
      "                                                                    'The seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'consists '\n",
      "                                                                    'of '\n",
      "                                                                    'positive '\n",
      "                                                                    'and '\n",
      "                                                                    'negative '\n",
      "                                                                    'predicates. '\n",
      "                                                                    'If the '\n",
      "                                                                    'predicate '\n",
      "                                                                    'of an '\n",
      "                                                                    'extracted '\n",
      "                                                                    'event is '\n",
      "                                                                    'in the '\n",
      "                                                                    'seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'and does '\n",
      "                                                                    'not '\n",
      "                                                                    'involve '\n",
      "                                                                    'complex '\n",
      "                                                                    'phenomena '\n",
      "                                                                    'like '\n",
      "                                                                    'negation, '\n",
      "                                                                    'we assign '\n",
      "                                                                    'the '\n",
      "                                                                    'corresponding '\n",
      "                                                                    'polarity '\n",
      "                                                                    'score '\n",
      "                                                                    '($+1$ for '\n",
      "                                                                    'positive '\n",
      "                                                                    'events '\n",
      "                                                                    'and $-1$ '\n",
      "                                                                    'for '\n",
      "                                                                    'negative '\n",
      "                                                                    'events) '\n",
      "                                                                    'to the '\n",
      "                                                                    'event. We '\n",
      "                                                                    'expect '\n",
      "                                                                    'the model '\n",
      "                                                                    'to '\n",
      "                                                                    'automatically '\n",
      "                                                                    'learn '\n",
      "                                                                    'complex '\n",
      "                                                                    'phenomena '\n",
      "                                                                    'through '\n",
      "                                                                    'label '\n",
      "                                                                    'propagation. '\n",
      "                                                                    'Based on '\n",
      "                                                                    'the '\n",
      "                                                                    'availability '\n",
      "                                                                    'of scores '\n",
      "                                                                    'and the '\n",
      "                                                                    'types of '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relations, '\n",
      "                                                                    'we '\n",
      "                                                                    'classify '\n",
      "                                                                    'the '\n",
      "                                                                    'extracted '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs '\n",
      "                                                                    'into the '\n",
      "                                                                    'following '\n",
      "                                                                    'three '\n",
      "                                                                    'types.'],\n",
      "                                                    'extractive_spans': [],\n",
      "                                                    'free_form_answer': 'cause '\n",
      "                                                                        'relation: '\n",
      "                                                                        'both '\n",
      "                                                                        'events '\n",
      "                                                                        'in '\n",
      "                                                                        'the '\n",
      "                                                                        'relation '\n",
      "                                                                        'should '\n",
      "                                                                        'have '\n",
      "                                                                        'the '\n",
      "                                                                        'same '\n",
      "                                                                        'polarity; '\n",
      "                                                                        'concession '\n",
      "                                                                        'relation: '\n",
      "                                                                        'events '\n",
      "                                                                        'should '\n",
      "                                                                        'have '\n",
      "                                                                        'opposite '\n",
      "                                                                        'polarity',\n",
      "                                                    'highlighted_evidence': [   'As '\n",
      "                                                                                'illustrated '\n",
      "                                                                                'in '\n",
      "                                                                                'Figure '\n",
      "                                                                                'FIGREF1, '\n",
      "                                                                                'our '\n",
      "                                                                                'key '\n",
      "                                                                                'idea '\n",
      "                                                                                'is '\n",
      "                                                                                'that '\n",
      "                                                                                'we '\n",
      "                                                                                'can '\n",
      "                                                                                'exploit '\n",
      "                                                                                'discourse '\n",
      "                                                                                'relations '\n",
      "                                                                                'BIBREF4 '\n",
      "                                                                                'to '\n",
      "                                                                                'efficiently '\n",
      "                                                                                'propagate '\n",
      "                                                                                'polarity '\n",
      "                                                                                'from '\n",
      "                                                                                'seed '\n",
      "                                                                                'predicates '\n",
      "                                                                                'that '\n",
      "                                                                                'directly '\n",
      "                                                                                'report '\n",
      "                                                                                \"one's \"\n",
      "                                                                                'emotions '\n",
      "                                                                                '(e.g., '\n",
      "                                                                                '“to '\n",
      "                                                                                'be '\n",
      "                                                                                'glad” '\n",
      "                                                                                'is '\n",
      "                                                                                'positive). '\n",
      "                                                                                'Suppose '\n",
      "                                                                                'that '\n",
      "                                                                                'events '\n",
      "                                                                                '$x_1$ '\n",
      "                                                                                'are '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'are '\n",
      "                                                                                'in '\n",
      "                                                                                'the '\n",
      "                                                                                'discourse '\n",
      "                                                                                'relation '\n",
      "                                                                                'of '\n",
      "                                                                                'Cause '\n",
      "                                                                                '(i.e., '\n",
      "                                                                                '$x_1$ '\n",
      "                                                                                'causes '\n",
      "                                                                                '$x_2$). '\n",
      "                                                                                'If '\n",
      "                                                                                'the '\n",
      "                                                                                'seed '\n",
      "                                                                                'lexicon '\n",
      "                                                                                'suggests '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'is '\n",
      "                                                                                'positive, '\n",
      "                                                                                '$x_1$ '\n",
      "                                                                                'is '\n",
      "                                                                                'also '\n",
      "                                                                                'likely '\n",
      "                                                                                'to '\n",
      "                                                                                'be '\n",
      "                                                                                'positive '\n",
      "                                                                                'because '\n",
      "                                                                                'it '\n",
      "                                                                                'triggers '\n",
      "                                                                                'the '\n",
      "                                                                                'positive '\n",
      "                                                                                'emotion. '\n",
      "                                                                                'The '\n",
      "                                                                                'fact '\n",
      "                                                                                'that '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'is '\n",
      "                                                                                'known '\n",
      "                                                                                'to '\n",
      "                                                                                'be '\n",
      "                                                                                'negative '\n",
      "                                                                                'indicates '\n",
      "                                                                                'the '\n",
      "                                                                                'negative '\n",
      "                                                                                'polarity '\n",
      "                                                                                'of '\n",
      "                                                                                '$x_1$. '\n",
      "                                                                                'Similarly, '\n",
      "                                                                                'if '\n",
      "                                                                                '$x_1$ '\n",
      "                                                                                'and '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'are '\n",
      "                                                                                'in '\n",
      "                                                                                'the '\n",
      "                                                                                'discourse '\n",
      "                                                                                'relation '\n",
      "                                                                                'of '\n",
      "                                                                                'Concession '\n",
      "                                                                                '(i.e., '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'in '\n",
      "                                                                                'spite '\n",
      "                                                                                'of '\n",
      "                                                                                '$x_1$), '\n",
      "                                                                                'the '\n",
      "                                                                                'reverse '\n",
      "                                                                                'of '\n",
      "                                                                                \"$x_2$'s \"\n",
      "                                                                                'polarity '\n",
      "                                                                                'can '\n",
      "                                                                                'be '\n",
      "                                                                                'propagated '\n",
      "                                                                                'to '\n",
      "                                                                                '$x_1$. '\n",
      "                                                                                'Even '\n",
      "                                                                                'if '\n",
      "                                                                                \"$x_2$'s \"\n",
      "                                                                                'polarity '\n",
      "                                                                                'is '\n",
      "                                                                                'not '\n",
      "                                                                                'known '\n",
      "                                                                                'in '\n",
      "                                                                                'advance, '\n",
      "                                                                                'we '\n",
      "                                                                                'can '\n",
      "                                                                                'exploit '\n",
      "                                                                                'the '\n",
      "                                                                                'tendency '\n",
      "                                                                                'of '\n",
      "                                                                                '$x_1$ '\n",
      "                                                                                'and '\n",
      "                                                                                '$x_2$ '\n",
      "                                                                                'to '\n",
      "                                                                                'be '\n",
      "                                                                                'of '\n",
      "                                                                                'the '\n",
      "                                                                                'same '\n",
      "                                                                                'polarity '\n",
      "                                                                                '(for '\n",
      "                                                                                'Cause) '\n",
      "                                                                                'or '\n",
      "                                                                                'of '\n",
      "                                                                                'the '\n",
      "                                                                                'reverse '\n",
      "                                                                                'polarity '\n",
      "                                                                                '(for '\n",
      "                                                                                'Concession) '\n",
      "                                                                                'although '\n",
      "                                                                                'the '\n",
      "                                                                                'heuristic '\n",
      "                                                                                'is '\n",
      "                                                                                'not '\n",
      "                                                                                'exempt '\n",
      "                                                                                'from '\n",
      "                                                                                'counterexamples. '\n",
      "                                                                                'We '\n",
      "                                                                                'transform '\n",
      "                                                                                'this '\n",
      "                                                                                'idea '\n",
      "                                                                                'into '\n",
      "                                                                                'objective '\n",
      "                                                                                'functions '\n",
      "                                                                                'and '\n",
      "                                                                                'train '\n",
      "                                                                                'neural '\n",
      "                                                                                'network '\n",
      "                                                                                'models '\n",
      "                                                                                'that '\n",
      "                                                                                'predict '\n",
      "                                                                                'the '\n",
      "                                                                                'polarity '\n",
      "                                                                                'of '\n",
      "                                                                                'a '\n",
      "                                                                                'given '\n",
      "                                                                                'event.',\n",
      "                                                                                'The '\n",
      "                                                                                'seed '\n",
      "                                                                                'lexicon '\n",
      "                                                                                'consists '\n",
      "                                                                                'of '\n",
      "                                                                                'positive '\n",
      "                                                                                'and '\n",
      "                                                                                'negative '\n",
      "                                                                                'predicates. '\n",
      "                                                                                'If '\n",
      "                                                                                'the '\n",
      "                                                                                'predicate '\n",
      "                                                                                'of '\n",
      "                                                                                'an '\n",
      "                                                                                'extracted '\n",
      "                                                                                'event '\n",
      "                                                                                'is '\n",
      "                                                                                'in '\n",
      "                                                                                'the '\n",
      "                                                                                'seed '\n",
      "                                                                                'lexicon '\n",
      "                                                                                'and '\n",
      "                                                                                'does '\n",
      "                                                                                'not '\n",
      "                                                                                'involve '\n",
      "                                                                                'complex '\n",
      "                                                                                'phenomena '\n",
      "                                                                                'like '\n",
      "                                                                                'negation, '\n",
      "                                                                                'we '\n",
      "                                                                                'assign '\n",
      "                                                                                'the '\n",
      "                                                                                'corresponding '\n",
      "                                                                                'polarity '\n",
      "                                                                                'score '\n",
      "                                                                                '($+1$ '\n",
      "                                                                                'for '\n",
      "                                                                                'positive '\n",
      "                                                                                'events '\n",
      "                                                                                'and '\n",
      "                                                                                '$-1$ '\n",
      "                                                                                'for '\n",
      "                                                                                'negative '\n",
      "                                                                                'events) '\n",
      "                                                                                'to '\n",
      "                                                                                'the '\n",
      "                                                                                'event. '\n",
      "                                                                                'We '\n",
      "                                                                                'expect '\n",
      "                                                                                'the '\n",
      "                                                                                'model '\n",
      "                                                                                'to '\n",
      "                                                                                'automatically '\n",
      "                                                                                'learn '\n",
      "                                                                                'complex '\n",
      "                                                                                'phenomena '\n",
      "                                                                                'through '\n",
      "                                                                                'label '\n",
      "                                                                                'propagation.'],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None}],\n",
      "                                  'worker_id': [   'c1fbdd7a261021041f75fbe00a55b4c386ebbbb4',\n",
      "                                                   '2cfd959e433f290bb50b55722370f0d22fe090b7']},\n",
      "                              {   'annotation_id': [   '36926a4c9e14352c91111150aa4c6edcc5c0770f',\n",
      "                                                       '75b6dd28ccab20a70087635d89c2b22d0e99095c'],\n",
      "                                  'answer': [   {   'evidence': [   'As a raw '\n",
      "                                                                    'corpus, '\n",
      "                                                                    'we used a '\n",
      "                                                                    'Japanese '\n",
      "                                                                    'web '\n",
      "                                                                    'corpus '\n",
      "                                                                    'that was '\n",
      "                                                                    'compiled '\n",
      "                                                                    'through '\n",
      "                                                                    'the '\n",
      "                                                                    'procedures '\n",
      "                                                                    'proposed '\n",
      "                                                                    'by '\n",
      "                                                                    'BIBREF13. '\n",
      "                                                                    'To '\n",
      "                                                                    'extract '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs '\n",
      "                                                                    'tagged '\n",
      "                                                                    'with '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relations, '\n",
      "                                                                    'we used '\n",
      "                                                                    'the '\n",
      "                                                                    'Japanese '\n",
      "                                                                    'dependency '\n",
      "                                                                    'parser '\n",
      "                                                                    'KNP and '\n",
      "                                                                    'in-house '\n",
      "                                                                    'postprocessing '\n",
      "                                                                    'scripts '\n",
      "                                                                    'BIBREF14. '\n",
      "                                                                    'KNP used '\n",
      "                                                                    'hand-written '\n",
      "                                                                    'rules to '\n",
      "                                                                    'segment '\n",
      "                                                                    'each '\n",
      "                                                                    'sentence '\n",
      "                                                                    'into what '\n",
      "                                                                    'we '\n",
      "                                                                    'conventionally '\n",
      "                                                                    'called '\n",
      "                                                                    'clauses '\n",
      "                                                                    '(mostly '\n",
      "                                                                    'consecutive '\n",
      "                                                                    'text '\n",
      "                                                                    'chunks), '\n",
      "                                                                    'each of '\n",
      "                                                                    'which '\n",
      "                                                                    'contained '\n",
      "                                                                    'one main '\n",
      "                                                                    'predicate. '\n",
      "                                                                    'KNP also '\n",
      "                                                                    'identified '\n",
      "                                                                    'the '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relations '\n",
      "                                                                    'of event '\n",
      "                                                                    'pairs if '\n",
      "                                                                    'explicit '\n",
      "                                                                    'discourse '\n",
      "                                                                    'connectives '\n",
      "                                                                    'BIBREF4 '\n",
      "                                                                    'such as '\n",
      "                                                                    '“ので” '\n",
      "                                                                    '(because) '\n",
      "                                                                    'and “のに” '\n",
      "                                                                    '(in spite '\n",
      "                                                                    'of) were '\n",
      "                                                                    'present. '\n",
      "                                                                    'We '\n",
      "                                                                    'treated '\n",
      "                                                                    'Cause/Reason '\n",
      "                                                                    '(原因・理由) '\n",
      "                                                                    'and '\n",
      "                                                                    'Condition '\n",
      "                                                                    '(条件) in '\n",
      "                                                                    'the '\n",
      "                                                                    'original '\n",
      "                                                                    'tagset '\n",
      "                                                                    'BIBREF15 '\n",
      "                                                                    'as Cause '\n",
      "                                                                    'and '\n",
      "                                                                    'Concession '\n",
      "                                                                    '(逆接) as '\n",
      "                                                                    'Concession, '\n",
      "                                                                    'respectively. '\n",
      "                                                                    'Here is '\n",
      "                                                                    'an '\n",
      "                                                                    'example '\n",
      "                                                                    'of event '\n",
      "                                                                    'pair '\n",
      "                                                                    'extraction.',\n",
      "                                                                    'We '\n",
      "                                                                    'constructed '\n",
      "                                                                    'our seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'consisting '\n",
      "                                                                    'of 15 '\n",
      "                                                                    'positive '\n",
      "                                                                    'words and '\n",
      "                                                                    '15 '\n",
      "                                                                    'negative '\n",
      "                                                                    'words, as '\n",
      "                                                                    'shown in '\n",
      "                                                                    'Section '\n",
      "                                                                    'SECREF27. '\n",
      "                                                                    'From the '\n",
      "                                                                    'corpus of '\n",
      "                                                                    'about 100 '\n",
      "                                                                    'million '\n",
      "                                                                    'sentences, '\n",
      "                                                                    'we '\n",
      "                                                                    'obtained '\n",
      "                                                                    '1.4 '\n",
      "                                                                    'millions '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs for '\n",
      "                                                                    'AL, 41 '\n",
      "                                                                    'millions '\n",
      "                                                                    'for CA, '\n",
      "                                                                    'and 6 '\n",
      "                                                                    'millions '\n",
      "                                                                    'for CO. '\n",
      "                                                                    'We '\n",
      "                                                                    'randomly '\n",
      "                                                                    'selected '\n",
      "                                                                    'subsets '\n",
      "                                                                    'of AL '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs '\n",
      "                                                                    'such that '\n",
      "                                                                    'positive '\n",
      "                                                                    'and '\n",
      "                                                                    'negative '\n",
      "                                                                    'latter '\n",
      "                                                                    'events '\n",
      "                                                                    'were '\n",
      "                                                                    'equal in '\n",
      "                                                                    'size. We '\n",
      "                                                                    'also '\n",
      "                                                                    'sampled '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs for '\n",
      "                                                                    'each of '\n",
      "                                                                    'CA and CO '\n",
      "                                                                    'such that '\n",
      "                                                                    'it was '\n",
      "                                                                    'five '\n",
      "                                                                    'times '\n",
      "                                                                    'larger '\n",
      "                                                                    'than AL. '\n",
      "                                                                    'The '\n",
      "                                                                    'results '\n",
      "                                                                    'are shown '\n",
      "                                                                    'in Table '\n",
      "                                                                    'TABREF16.',\n",
      "                                                                    'FLOAT '\n",
      "                                                                    'SELECTED: '\n",
      "                                                                    'Table 1: '\n",
      "                                                                    'Statistics '\n",
      "                                                                    'of the '\n",
      "                                                                    'AL, CA, '\n",
      "                                                                    'and CO '\n",
      "                                                                    'datasets.',\n",
      "                                                                    'We used '\n",
      "                                                                    'the '\n",
      "                                                                    'latest '\n",
      "                                                                    'version '\n",
      "                                                                    'of the '\n",
      "                                                                    'ACP '\n",
      "                                                                    'Corpus '\n",
      "                                                                    'BIBREF12 '\n",
      "                                                                    'for '\n",
      "                                                                    'evaluation. '\n",
      "                                                                    'It was '\n",
      "                                                                    'used for '\n",
      "                                                                    '(semi-)supervised '\n",
      "                                                                    'training '\n",
      "                                                                    'as well. '\n",
      "                                                                    'Extracted '\n",
      "                                                                    'from '\n",
      "                                                                    'Japanese '\n",
      "                                                                    'websites '\n",
      "                                                                    'using '\n",
      "                                                                    'HTML '\n",
      "                                                                    'layouts '\n",
      "                                                                    'and '\n",
      "                                                                    'linguistic '\n",
      "                                                                    'patterns, '\n",
      "                                                                    'the '\n",
      "                                                                    'dataset '\n",
      "                                                                    'covered '\n",
      "                                                                    'various '\n",
      "                                                                    'genres. '\n",
      "                                                                    'For '\n",
      "                                                                    'example, '\n",
      "                                                                    'the '\n",
      "                                                                    'following '\n",
      "                                                                    'two '\n",
      "                                                                    'sentences '\n",
      "                                                                    'were '\n",
      "                                                                    'labeled '\n",
      "                                                                    'positive '\n",
      "                                                                    'and '\n",
      "                                                                    'negative, '\n",
      "                                                                    'respectively:',\n",
      "                                                                    'Although '\n",
      "                                                                    'the ACP '\n",
      "                                                                    'corpus '\n",
      "                                                                    'was '\n",
      "                                                                    'originally '\n",
      "                                                                    'constructed '\n",
      "                                                                    'in the '\n",
      "                                                                    'context '\n",
      "                                                                    'of '\n",
      "                                                                    'sentiment '\n",
      "                                                                    'analysis, '\n",
      "                                                                    'we found '\n",
      "                                                                    'that it '\n",
      "                                                                    'could '\n",
      "                                                                    'roughly '\n",
      "                                                                    'be '\n",
      "                                                                    'regarded '\n",
      "                                                                    'as a '\n",
      "                                                                    'collection '\n",
      "                                                                    'of '\n",
      "                                                                    'affective '\n",
      "                                                                    'events. '\n",
      "                                                                    'We parsed '\n",
      "                                                                    'each '\n",
      "                                                                    'sentence '\n",
      "                                                                    'and '\n",
      "                                                                    'extracted '\n",
      "                                                                    'the last '\n",
      "                                                                    'clause in '\n",
      "                                                                    'it. The '\n",
      "                                                                    'train/dev/test '\n",
      "                                                                    'split of '\n",
      "                                                                    'the data '\n",
      "                                                                    'is shown '\n",
      "                                                                    'in Table '\n",
      "                                                                    'TABREF19.',\n",
      "                                                                    'FLOAT '\n",
      "                                                                    'SELECTED: '\n",
      "                                                                    'Table 2: '\n",
      "                                                                    'Details '\n",
      "                                                                    'of the '\n",
      "                                                                    'ACP '\n",
      "                                                                    'dataset.'],\n",
      "                                                    'extractive_spans': [],\n",
      "                                                    'free_form_answer': '7000000 '\n",
      "                                                                        'pairs '\n",
      "                                                                        'of '\n",
      "                                                                        'events '\n",
      "                                                                        'were '\n",
      "                                                                        'extracted '\n",
      "                                                                        'from '\n",
      "                                                                        'the '\n",
      "                                                                        'Japanese '\n",
      "                                                                        'Web '\n",
      "                                                                        'corpus, '\n",
      "                                                                        '529850 '\n",
      "                                                                        'pairs '\n",
      "                                                                        'of '\n",
      "                                                                        'events '\n",
      "                                                                        'were '\n",
      "                                                                        'extracted '\n",
      "                                                                        'from '\n",
      "                                                                        'the '\n",
      "                                                                        'ACP '\n",
      "                                                                        'corpus',\n",
      "                                                    'highlighted_evidence': [   'As '\n",
      "                                                                                'a '\n",
      "                                                                                'raw '\n",
      "                                                                                'corpus, '\n",
      "                                                                                'we '\n",
      "                                                                                'used '\n",
      "                                                                                'a '\n",
      "                                                                                'Japanese '\n",
      "                                                                                'web '\n",
      "                                                                                'corpus '\n",
      "                                                                                'that '\n",
      "                                                                                'was '\n",
      "                                                                                'compiled '\n",
      "                                                                                'through '\n",
      "                                                                                'the '\n",
      "                                                                                'procedures '\n",
      "                                                                                'proposed '\n",
      "                                                                                'by '\n",
      "                                                                                'BIBREF13. ',\n",
      "                                                                                'From '\n",
      "                                                                                'the '\n",
      "                                                                                'corpus '\n",
      "                                                                                'of '\n",
      "                                                                                'about '\n",
      "                                                                                '100 '\n",
      "                                                                                'million '\n",
      "                                                                                'sentences, '\n",
      "                                                                                'we '\n",
      "                                                                                'obtained '\n",
      "                                                                                '1.4 '\n",
      "                                                                                'millions '\n",
      "                                                                                'event '\n",
      "                                                                                'pairs '\n",
      "                                                                                'for '\n",
      "                                                                                'AL, '\n",
      "                                                                                '41 '\n",
      "                                                                                'millions '\n",
      "                                                                                'for '\n",
      "                                                                                'CA, '\n",
      "                                                                                'and '\n",
      "                                                                                '6 '\n",
      "                                                                                'millions '\n",
      "                                                                                'for '\n",
      "                                                                                'CO. '\n",
      "                                                                                'We '\n",
      "                                                                                'randomly '\n",
      "                                                                                'selected '\n",
      "                                                                                'subsets '\n",
      "                                                                                'of '\n",
      "                                                                                'AL '\n",
      "                                                                                'event '\n",
      "                                                                                'pairs '\n",
      "                                                                                'such '\n",
      "                                                                                'that '\n",
      "                                                                                'positive '\n",
      "                                                                                'and '\n",
      "                                                                                'negative '\n",
      "                                                                                'latter '\n",
      "                                                                                'events '\n",
      "                                                                                'were '\n",
      "                                                                                'equal '\n",
      "                                                                                'in '\n",
      "                                                                                'size. '\n",
      "                                                                                'We '\n",
      "                                                                                'also '\n",
      "                                                                                'sampled '\n",
      "                                                                                'event '\n",
      "                                                                                'pairs '\n",
      "                                                                                'for '\n",
      "                                                                                'each '\n",
      "                                                                                'of '\n",
      "                                                                                'CA '\n",
      "                                                                                'and '\n",
      "                                                                                'CO '\n",
      "                                                                                'such '\n",
      "                                                                                'that '\n",
      "                                                                                'it '\n",
      "                                                                                'was '\n",
      "                                                                                'five '\n",
      "                                                                                'times '\n",
      "                                                                                'larger '\n",
      "                                                                                'than '\n",
      "                                                                                'AL. '\n",
      "                                                                                'The '\n",
      "                                                                                'results '\n",
      "                                                                                'are '\n",
      "                                                                                'shown '\n",
      "                                                                                'in '\n",
      "                                                                                'Table '\n",
      "                                                                                'TABREF16.',\n",
      "                                                                                'FLOAT '\n",
      "                                                                                'SELECTED: '\n",
      "                                                                                'Table '\n",
      "                                                                                '1: '\n",
      "                                                                                'Statistics '\n",
      "                                                                                'of '\n",
      "                                                                                'the '\n",
      "                                                                                'AL, '\n",
      "                                                                                'CA, '\n",
      "                                                                                'and '\n",
      "                                                                                'CO '\n",
      "                                                                                'datasets.',\n",
      "                                                                                'We '\n",
      "                                                                                'used '\n",
      "                                                                                'the '\n",
      "                                                                                'latest '\n",
      "                                                                                'version '\n",
      "                                                                                'of '\n",
      "                                                                                'the '\n",
      "                                                                                'ACP '\n",
      "                                                                                'Corpus '\n",
      "                                                                                'BIBREF12 '\n",
      "                                                                                'for '\n",
      "                                                                                'evaluation. '\n",
      "                                                                                'It '\n",
      "                                                                                'was '\n",
      "                                                                                'used '\n",
      "                                                                                'for '\n",
      "                                                                                '(semi-)supervised '\n",
      "                                                                                'training '\n",
      "                                                                                'as '\n",
      "                                                                                'well.',\n",
      "                                                                                'Although '\n",
      "                                                                                'the '\n",
      "                                                                                'ACP '\n",
      "                                                                                'corpus '\n",
      "                                                                                'was '\n",
      "                                                                                'originally '\n",
      "                                                                                'constructed '\n",
      "                                                                                'in '\n",
      "                                                                                'the '\n",
      "                                                                                'context '\n",
      "                                                                                'of '\n",
      "                                                                                'sentiment '\n",
      "                                                                                'analysis, '\n",
      "                                                                                'we '\n",
      "                                                                                'found '\n",
      "                                                                                'that '\n",
      "                                                                                'it '\n",
      "                                                                                'could '\n",
      "                                                                                'roughly '\n",
      "                                                                                'be '\n",
      "                                                                                'regarded '\n",
      "                                                                                'as '\n",
      "                                                                                'a '\n",
      "                                                                                'collection '\n",
      "                                                                                'of '\n",
      "                                                                                'affective '\n",
      "                                                                                'events. '\n",
      "                                                                                'We '\n",
      "                                                                                'parsed '\n",
      "                                                                                'each '\n",
      "                                                                                'sentence '\n",
      "                                                                                'and '\n",
      "                                                                                'extracted '\n",
      "                                                                                'the '\n",
      "                                                                                'last '\n",
      "                                                                                'clause '\n",
      "                                                                                'in '\n",
      "                                                                                'it. '\n",
      "                                                                                'The '\n",
      "                                                                                'train/dev/test '\n",
      "                                                                                'split '\n",
      "                                                                                'of '\n",
      "                                                                                'the '\n",
      "                                                                                'data '\n",
      "                                                                                'is '\n",
      "                                                                                'shown '\n",
      "                                                                                'in '\n",
      "                                                                                'Table '\n",
      "                                                                                'TABREF19.',\n",
      "                                                                                'FLOAT '\n",
      "                                                                                'SELECTED: '\n",
      "                                                                                'Table '\n",
      "                                                                                '2: '\n",
      "                                                                                'Details '\n",
      "                                                                                'of '\n",
      "                                                                                'the '\n",
      "                                                                                'ACP '\n",
      "                                                                                'dataset.'],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None},\n",
      "                                                {   'evidence': [   'FLOAT '\n",
      "                                                                    'SELECTED: '\n",
      "                                                                    'Table 2: '\n",
      "                                                                    'Details '\n",
      "                                                                    'of the '\n",
      "                                                                    'ACP '\n",
      "                                                                    'dataset.'],\n",
      "                                                    'extractive_spans': [],\n",
      "                                                    'free_form_answer': 'The '\n",
      "                                                                        'ACP '\n",
      "                                                                        'corpus '\n",
      "                                                                        'has '\n",
      "                                                                        'around '\n",
      "                                                                        '700k '\n",
      "                                                                        'events '\n",
      "                                                                        'split '\n",
      "                                                                        'into '\n",
      "                                                                        'positive '\n",
      "                                                                        'and '\n",
      "                                                                        'negative '\n",
      "                                                                        'polarity ',\n",
      "                                                    'highlighted_evidence': [   'FLOAT '\n",
      "                                                                                'SELECTED: '\n",
      "                                                                                'Table '\n",
      "                                                                                '2: '\n",
      "                                                                                'Details '\n",
      "                                                                                'of '\n",
      "                                                                                'the '\n",
      "                                                                                'ACP '\n",
      "                                                                                'dataset.'],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None}],\n",
      "                                  'worker_id': [   '2cfd959e433f290bb50b55722370f0d22fe090b7',\n",
      "                                                   'c1fbdd7a261021041f75fbe00a55b4c386ebbbb4']},\n",
      "                              {   'annotation_id': [   '2d8c7df145c37aad905e48f64d8caa69e54434d4'],\n",
      "                                  'answer': [   {   'evidence': [   'Affective '\n",
      "                                                                    'events '\n",
      "                                                                    'BIBREF0 '\n",
      "                                                                    'are '\n",
      "                                                                    'events '\n",
      "                                                                    'that '\n",
      "                                                                    'typically '\n",
      "                                                                    'affect '\n",
      "                                                                    'people in '\n",
      "                                                                    'positive '\n",
      "                                                                    'or '\n",
      "                                                                    'negative '\n",
      "                                                                    'ways. For '\n",
      "                                                                    'example, '\n",
      "                                                                    'getting '\n",
      "                                                                    'money and '\n",
      "                                                                    'playing '\n",
      "                                                                    'sports '\n",
      "                                                                    'are '\n",
      "                                                                    'usually '\n",
      "                                                                    'positive '\n",
      "                                                                    'to the '\n",
      "                                                                    'experiencers; '\n",
      "                                                                    'catching '\n",
      "                                                                    'cold and '\n",
      "                                                                    'losing '\n",
      "                                                                    \"one's \"\n",
      "                                                                    'wallet '\n",
      "                                                                    'are '\n",
      "                                                                    'negative. '\n",
      "                                                                    'Understanding '\n",
      "                                                                    'affective '\n",
      "                                                                    'events is '\n",
      "                                                                    'important '\n",
      "                                                                    'to '\n",
      "                                                                    'various '\n",
      "                                                                    'natural '\n",
      "                                                                    'language '\n",
      "                                                                    'processing '\n",
      "                                                                    '(NLP) '\n",
      "                                                                    'applications '\n",
      "                                                                    'such as '\n",
      "                                                                    'dialogue '\n",
      "                                                                    'systems '\n",
      "                                                                    'BIBREF1, '\n",
      "                                                                    'question-answering '\n",
      "                                                                    'systems '\n",
      "                                                                    'BIBREF2, '\n",
      "                                                                    'and humor '\n",
      "                                                                    'recognition '\n",
      "                                                                    'BIBREF3. '\n",
      "                                                                    'In this '\n",
      "                                                                    'paper, we '\n",
      "                                                                    'work on '\n",
      "                                                                    'recognizing '\n",
      "                                                                    'the '\n",
      "                                                                    'polarity '\n",
      "                                                                    'of an '\n",
      "                                                                    'affective '\n",
      "                                                                    'event '\n",
      "                                                                    'that is '\n",
      "                                                                    'represented '\n",
      "                                                                    'by a '\n",
      "                                                                    'score '\n",
      "                                                                    'ranging '\n",
      "                                                                    'from $-1$ '\n",
      "                                                                    '(negative) '\n",
      "                                                                    'to 1 '\n",
      "                                                                    '(positive).'],\n",
      "                                                    'extractive_spans': [   'negative',\n",
      "                                                                            'positive'],\n",
      "                                                    'free_form_answer': '',\n",
      "                                                    'highlighted_evidence': [   'In '\n",
      "                                                                                'this '\n",
      "                                                                                'paper, '\n",
      "                                                                                'we '\n",
      "                                                                                'work '\n",
      "                                                                                'on '\n",
      "                                                                                'recognizing '\n",
      "                                                                                'the '\n",
      "                                                                                'polarity '\n",
      "                                                                                'of '\n",
      "                                                                                'an '\n",
      "                                                                                'affective '\n",
      "                                                                                'event '\n",
      "                                                                                'that '\n",
      "                                                                                'is '\n",
      "                                                                                'represented '\n",
      "                                                                                'by '\n",
      "                                                                                'a '\n",
      "                                                                                'score '\n",
      "                                                                                'ranging '\n",
      "                                                                                'from '\n",
      "                                                                                '$-1$ '\n",
      "                                                                                '(negative) '\n",
      "                                                                                'to '\n",
      "                                                                                '1 '\n",
      "                                                                                '(positive).'],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None}],\n",
      "                                  'worker_id': [   'c1018a31c3272ce74964a3280069f62f314a1a58']},\n",
      "                              {   'annotation_id': [   'df4372b2e8d9bb2039a5582f192768953b01d904'],\n",
      "                                  'answer': [   {   'evidence': [   'FLOAT '\n",
      "                                                                    'SELECTED: '\n",
      "                                                                    'Table 4: '\n",
      "                                                                    'Results '\n",
      "                                                                    'for small '\n",
      "                                                                    'labeled '\n",
      "                                                                    'training '\n",
      "                                                                    'data. '\n",
      "                                                                    'Given the '\n",
      "                                                                    'performance '\n",
      "                                                                    'with the '\n",
      "                                                                    'full '\n",
      "                                                                    'dataset, '\n",
      "                                                                    'we show '\n",
      "                                                                    'BERT '\n",
      "                                                                    'trained '\n",
      "                                                                    'only with '\n",
      "                                                                    'the AL '\n",
      "                                                                    'data.'],\n",
      "                                                    'extractive_spans': [],\n",
      "                                                    'free_form_answer': '3%',\n",
      "                                                    'highlighted_evidence': [   'FLOAT '\n",
      "                                                                                'SELECTED: '\n",
      "                                                                                'Table '\n",
      "                                                                                '4: '\n",
      "                                                                                'Results '\n",
      "                                                                                'for '\n",
      "                                                                                'small '\n",
      "                                                                                'labeled '\n",
      "                                                                                'training '\n",
      "                                                                                'data. '\n",
      "                                                                                'Given '\n",
      "                                                                                'the '\n",
      "                                                                                'performance '\n",
      "                                                                                'with '\n",
      "                                                                                'the '\n",
      "                                                                                'full '\n",
      "                                                                                'dataset, '\n",
      "                                                                                'we '\n",
      "                                                                                'show '\n",
      "                                                                                'BERT '\n",
      "                                                                                'trained '\n",
      "                                                                                'only '\n",
      "                                                                                'with '\n",
      "                                                                                'the '\n",
      "                                                                                'AL '\n",
      "                                                                                'data.'],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None}],\n",
      "                                  'worker_id': [   'c1018a31c3272ce74964a3280069f62f314a1a58']},\n",
      "                              {   'annotation_id': [   '5c5bbc8af91c16af89b4ddd57ee6834be018e4e7'],\n",
      "                                  'answer': [   {   'evidence': [   'In this '\n",
      "                                                                    'paper, we '\n",
      "                                                                    'propose a '\n",
      "                                                                    'simple '\n",
      "                                                                    'and '\n",
      "                                                                    'effective '\n",
      "                                                                    'method '\n",
      "                                                                    'for '\n",
      "                                                                    'learning '\n",
      "                                                                    'affective '\n",
      "                                                                    'events '\n",
      "                                                                    'that only '\n",
      "                                                                    'requires '\n",
      "                                                                    'a very '\n",
      "                                                                    'small '\n",
      "                                                                    'seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'and a '\n",
      "                                                                    'large raw '\n",
      "                                                                    'corpus. '\n",
      "                                                                    'As '\n",
      "                                                                    'illustrated '\n",
      "                                                                    'in Figure '\n",
      "                                                                    'FIGREF1, '\n",
      "                                                                    'our key '\n",
      "                                                                    'idea is '\n",
      "                                                                    'that we '\n",
      "                                                                    'can '\n",
      "                                                                    'exploit '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relations '\n",
      "                                                                    'BIBREF4 '\n",
      "                                                                    'to '\n",
      "                                                                    'efficiently '\n",
      "                                                                    'propagate '\n",
      "                                                                    'polarity '\n",
      "                                                                    'from seed '\n",
      "                                                                    'predicates '\n",
      "                                                                    'that '\n",
      "                                                                    'directly '\n",
      "                                                                    'report '\n",
      "                                                                    \"one's \"\n",
      "                                                                    'emotions '\n",
      "                                                                    '(e.g., '\n",
      "                                                                    '“to be '\n",
      "                                                                    'glad” is '\n",
      "                                                                    'positive). '\n",
      "                                                                    'Suppose '\n",
      "                                                                    'that '\n",
      "                                                                    'events '\n",
      "                                                                    '$x_1$ are '\n",
      "                                                                    '$x_2$ are '\n",
      "                                                                    'in the '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relation '\n",
      "                                                                    'of Cause '\n",
      "                                                                    '(i.e., '\n",
      "                                                                    '$x_1$ '\n",
      "                                                                    'causes '\n",
      "                                                                    '$x_2$). '\n",
      "                                                                    'If the '\n",
      "                                                                    'seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'suggests '\n",
      "                                                                    '$x_2$ is '\n",
      "                                                                    'positive, '\n",
      "                                                                    '$x_1$ is '\n",
      "                                                                    'also '\n",
      "                                                                    'likely to '\n",
      "                                                                    'be '\n",
      "                                                                    'positive '\n",
      "                                                                    'because '\n",
      "                                                                    'it '\n",
      "                                                                    'triggers '\n",
      "                                                                    'the '\n",
      "                                                                    'positive '\n",
      "                                                                    'emotion. '\n",
      "                                                                    'The fact '\n",
      "                                                                    'that '\n",
      "                                                                    '$x_2$ is '\n",
      "                                                                    'known to '\n",
      "                                                                    'be '\n",
      "                                                                    'negative '\n",
      "                                                                    'indicates '\n",
      "                                                                    'the '\n",
      "                                                                    'negative '\n",
      "                                                                    'polarity '\n",
      "                                                                    'of $x_1$. '\n",
      "                                                                    'Similarly, '\n",
      "                                                                    'if $x_1$ '\n",
      "                                                                    'and $x_2$ '\n",
      "                                                                    'are in '\n",
      "                                                                    'the '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relation '\n",
      "                                                                    'of '\n",
      "                                                                    'Concession '\n",
      "                                                                    '(i.e., '\n",
      "                                                                    '$x_2$ in '\n",
      "                                                                    'spite of '\n",
      "                                                                    '$x_1$), '\n",
      "                                                                    'the '\n",
      "                                                                    'reverse '\n",
      "                                                                    'of '\n",
      "                                                                    \"$x_2$'s \"\n",
      "                                                                    'polarity '\n",
      "                                                                    'can be '\n",
      "                                                                    'propagated '\n",
      "                                                                    'to $x_1$. '\n",
      "                                                                    'Even if '\n",
      "                                                                    \"$x_2$'s \"\n",
      "                                                                    'polarity '\n",
      "                                                                    'is not '\n",
      "                                                                    'known in '\n",
      "                                                                    'advance, '\n",
      "                                                                    'we can '\n",
      "                                                                    'exploit '\n",
      "                                                                    'the '\n",
      "                                                                    'tendency '\n",
      "                                                                    'of $x_1$ '\n",
      "                                                                    'and $x_2$ '\n",
      "                                                                    'to be of '\n",
      "                                                                    'the same '\n",
      "                                                                    'polarity '\n",
      "                                                                    '(for '\n",
      "                                                                    'Cause) or '\n",
      "                                                                    'of the '\n",
      "                                                                    'reverse '\n",
      "                                                                    'polarity '\n",
      "                                                                    '(for '\n",
      "                                                                    'Concession) '\n",
      "                                                                    'although '\n",
      "                                                                    'the '\n",
      "                                                                    'heuristic '\n",
      "                                                                    'is not '\n",
      "                                                                    'exempt '\n",
      "                                                                    'from '\n",
      "                                                                    'counterexamples. '\n",
      "                                                                    'We '\n",
      "                                                                    'transform '\n",
      "                                                                    'this idea '\n",
      "                                                                    'into '\n",
      "                                                                    'objective '\n",
      "                                                                    'functions '\n",
      "                                                                    'and train '\n",
      "                                                                    'neural '\n",
      "                                                                    'network '\n",
      "                                                                    'models '\n",
      "                                                                    'that '\n",
      "                                                                    'predict '\n",
      "                                                                    'the '\n",
      "                                                                    'polarity '\n",
      "                                                                    'of a '\n",
      "                                                                    'given '\n",
      "                                                                    'event.'],\n",
      "                                                    'extractive_spans': [],\n",
      "                                                    'free_form_answer': 'by '\n",
      "                                                                        'exploiting '\n",
      "                                                                        'discourse '\n",
      "                                                                        'relations '\n",
      "                                                                        'to '\n",
      "                                                                        'propagate '\n",
      "                                                                        'polarity '\n",
      "                                                                        'from '\n",
      "                                                                        'seed '\n",
      "                                                                        'predicates '\n",
      "                                                                        'to '\n",
      "                                                                        'final '\n",
      "                                                                        'sentiment '\n",
      "                                                                        'polarity',\n",
      "                                                    'highlighted_evidence': [   'In '\n",
      "                                                                                'this '\n",
      "                                                                                'paper, '\n",
      "                                                                                'we '\n",
      "                                                                                'propose '\n",
      "                                                                                'a '\n",
      "                                                                                'simple '\n",
      "                                                                                'and '\n",
      "                                                                                'effective '\n",
      "                                                                                'method '\n",
      "                                                                                'for '\n",
      "                                                                                'learning '\n",
      "                                                                                'affective '\n",
      "                                                                                'events '\n",
      "                                                                                'that '\n",
      "                                                                                'only '\n",
      "                                                                                'requires '\n",
      "                                                                                'a '\n",
      "                                                                                'very '\n",
      "                                                                                'small '\n",
      "                                                                                'seed '\n",
      "                                                                                'lexicon '\n",
      "                                                                                'and '\n",
      "                                                                                'a '\n",
      "                                                                                'large '\n",
      "                                                                                'raw '\n",
      "                                                                                'corpus. '\n",
      "                                                                                'As '\n",
      "                                                                                'illustrated '\n",
      "                                                                                'in '\n",
      "                                                                                'Figure '\n",
      "                                                                                'FIGREF1, '\n",
      "                                                                                'our '\n",
      "                                                                                'key '\n",
      "                                                                                'idea '\n",
      "                                                                                'is '\n",
      "                                                                                'that '\n",
      "                                                                                'we '\n",
      "                                                                                'can '\n",
      "                                                                                'exploit '\n",
      "                                                                                'discourse '\n",
      "                                                                                'relations '\n",
      "                                                                                'BIBREF4 '\n",
      "                                                                                'to '\n",
      "                                                                                'efficiently '\n",
      "                                                                                'propagate '\n",
      "                                                                                'polarity '\n",
      "                                                                                'from '\n",
      "                                                                                'seed '\n",
      "                                                                                'predicates '\n",
      "                                                                                'that '\n",
      "                                                                                'directly '\n",
      "                                                                                'report '\n",
      "                                                                                \"one's \"\n",
      "                                                                                'emotions '\n",
      "                                                                                '(e.g., '\n",
      "                                                                                '“to '\n",
      "                                                                                'be '\n",
      "                                                                                'glad” '\n",
      "                                                                                'is '\n",
      "                                                                                'positive).'],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None}],\n",
      "                                  'worker_id': [   'c1018a31c3272ce74964a3280069f62f314a1a58']},\n",
      "                              {   'annotation_id': [   '0206f2131f64a3e02498cedad1250971b78ffd0c'],\n",
      "                                  'answer': [   {   'evidence': [   'We '\n",
      "                                                                    'constructed '\n",
      "                                                                    'our seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'consisting '\n",
      "                                                                    'of 15 '\n",
      "                                                                    'positive '\n",
      "                                                                    'words and '\n",
      "                                                                    '15 '\n",
      "                                                                    'negative '\n",
      "                                                                    'words, as '\n",
      "                                                                    'shown in '\n",
      "                                                                    'Section '\n",
      "                                                                    'SECREF27. '\n",
      "                                                                    'From the '\n",
      "                                                                    'corpus of '\n",
      "                                                                    'about 100 '\n",
      "                                                                    'million '\n",
      "                                                                    'sentences, '\n",
      "                                                                    'we '\n",
      "                                                                    'obtained '\n",
      "                                                                    '1.4 '\n",
      "                                                                    'millions '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs for '\n",
      "                                                                    'AL, 41 '\n",
      "                                                                    'millions '\n",
      "                                                                    'for CA, '\n",
      "                                                                    'and 6 '\n",
      "                                                                    'millions '\n",
      "                                                                    'for CO. '\n",
      "                                                                    'We '\n",
      "                                                                    'randomly '\n",
      "                                                                    'selected '\n",
      "                                                                    'subsets '\n",
      "                                                                    'of AL '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs '\n",
      "                                                                    'such that '\n",
      "                                                                    'positive '\n",
      "                                                                    'and '\n",
      "                                                                    'negative '\n",
      "                                                                    'latter '\n",
      "                                                                    'events '\n",
      "                                                                    'were '\n",
      "                                                                    'equal in '\n",
      "                                                                    'size. We '\n",
      "                                                                    'also '\n",
      "                                                                    'sampled '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs for '\n",
      "                                                                    'each of '\n",
      "                                                                    'CA and CO '\n",
      "                                                                    'such that '\n",
      "                                                                    'it was '\n",
      "                                                                    'five '\n",
      "                                                                    'times '\n",
      "                                                                    'larger '\n",
      "                                                                    'than AL. '\n",
      "                                                                    'The '\n",
      "                                                                    'results '\n",
      "                                                                    'are shown '\n",
      "                                                                    'in Table '\n",
      "                                                                    'TABREF16.'],\n",
      "                                                    'extractive_spans': [],\n",
      "                                                    'free_form_answer': '30 '\n",
      "                                                                        'words',\n",
      "                                                    'highlighted_evidence': [   'We '\n",
      "                                                                                'constructed '\n",
      "                                                                                'our '\n",
      "                                                                                'seed '\n",
      "                                                                                'lexicon '\n",
      "                                                                                'consisting '\n",
      "                                                                                'of '\n",
      "                                                                                '15 '\n",
      "                                                                                'positive '\n",
      "                                                                                'words '\n",
      "                                                                                'and '\n",
      "                                                                                '15 '\n",
      "                                                                                'negative '\n",
      "                                                                                'words, '\n",
      "                                                                                'as '\n",
      "                                                                                'shown '\n",
      "                                                                                'in '\n",
      "                                                                                'Section '\n",
      "                                                                                'SECREF27. '],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None}],\n",
      "                                  'worker_id': [   'c1018a31c3272ce74964a3280069f62f314a1a58']},\n",
      "                              {   'annotation_id': [   'c36bad2758c4f9866d64c357c475d370595d937f'],\n",
      "                                  'answer': [   {   'evidence': [   'As a raw '\n",
      "                                                                    'corpus, '\n",
      "                                                                    'we used a '\n",
      "                                                                    'Japanese '\n",
      "                                                                    'web '\n",
      "                                                                    'corpus '\n",
      "                                                                    'that was '\n",
      "                                                                    'compiled '\n",
      "                                                                    'through '\n",
      "                                                                    'the '\n",
      "                                                                    'procedures '\n",
      "                                                                    'proposed '\n",
      "                                                                    'by '\n",
      "                                                                    'BIBREF13. '\n",
      "                                                                    'To '\n",
      "                                                                    'extract '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs '\n",
      "                                                                    'tagged '\n",
      "                                                                    'with '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relations, '\n",
      "                                                                    'we used '\n",
      "                                                                    'the '\n",
      "                                                                    'Japanese '\n",
      "                                                                    'dependency '\n",
      "                                                                    'parser '\n",
      "                                                                    'KNP and '\n",
      "                                                                    'in-house '\n",
      "                                                                    'postprocessing '\n",
      "                                                                    'scripts '\n",
      "                                                                    'BIBREF14. '\n",
      "                                                                    'KNP used '\n",
      "                                                                    'hand-written '\n",
      "                                                                    'rules to '\n",
      "                                                                    'segment '\n",
      "                                                                    'each '\n",
      "                                                                    'sentence '\n",
      "                                                                    'into what '\n",
      "                                                                    'we '\n",
      "                                                                    'conventionally '\n",
      "                                                                    'called '\n",
      "                                                                    'clauses '\n",
      "                                                                    '(mostly '\n",
      "                                                                    'consecutive '\n",
      "                                                                    'text '\n",
      "                                                                    'chunks), '\n",
      "                                                                    'each of '\n",
      "                                                                    'which '\n",
      "                                                                    'contained '\n",
      "                                                                    'one main '\n",
      "                                                                    'predicate. '\n",
      "                                                                    'KNP also '\n",
      "                                                                    'identified '\n",
      "                                                                    'the '\n",
      "                                                                    'discourse '\n",
      "                                                                    'relations '\n",
      "                                                                    'of event '\n",
      "                                                                    'pairs if '\n",
      "                                                                    'explicit '\n",
      "                                                                    'discourse '\n",
      "                                                                    'connectives '\n",
      "                                                                    'BIBREF4 '\n",
      "                                                                    'such as '\n",
      "                                                                    '“ので” '\n",
      "                                                                    '(because) '\n",
      "                                                                    'and “のに” '\n",
      "                                                                    '(in spite '\n",
      "                                                                    'of) were '\n",
      "                                                                    'present. '\n",
      "                                                                    'We '\n",
      "                                                                    'treated '\n",
      "                                                                    'Cause/Reason '\n",
      "                                                                    '(原因・理由) '\n",
      "                                                                    'and '\n",
      "                                                                    'Condition '\n",
      "                                                                    '(条件) in '\n",
      "                                                                    'the '\n",
      "                                                                    'original '\n",
      "                                                                    'tagset '\n",
      "                                                                    'BIBREF15 '\n",
      "                                                                    'as Cause '\n",
      "                                                                    'and '\n",
      "                                                                    'Concession '\n",
      "                                                                    '(逆接) as '\n",
      "                                                                    'Concession, '\n",
      "                                                                    'respectively. '\n",
      "                                                                    'Here is '\n",
      "                                                                    'an '\n",
      "                                                                    'example '\n",
      "                                                                    'of event '\n",
      "                                                                    'pair '\n",
      "                                                                    'extraction.',\n",
      "                                                                    'We '\n",
      "                                                                    'constructed '\n",
      "                                                                    'our seed '\n",
      "                                                                    'lexicon '\n",
      "                                                                    'consisting '\n",
      "                                                                    'of 15 '\n",
      "                                                                    'positive '\n",
      "                                                                    'words and '\n",
      "                                                                    '15 '\n",
      "                                                                    'negative '\n",
      "                                                                    'words, as '\n",
      "                                                                    'shown in '\n",
      "                                                                    'Section '\n",
      "                                                                    'SECREF27. '\n",
      "                                                                    'From the '\n",
      "                                                                    'corpus of '\n",
      "                                                                    'about 100 '\n",
      "                                                                    'million '\n",
      "                                                                    'sentences, '\n",
      "                                                                    'we '\n",
      "                                                                    'obtained '\n",
      "                                                                    '1.4 '\n",
      "                                                                    'millions '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs for '\n",
      "                                                                    'AL, 41 '\n",
      "                                                                    'millions '\n",
      "                                                                    'for CA, '\n",
      "                                                                    'and 6 '\n",
      "                                                                    'millions '\n",
      "                                                                    'for CO. '\n",
      "                                                                    'We '\n",
      "                                                                    'randomly '\n",
      "                                                                    'selected '\n",
      "                                                                    'subsets '\n",
      "                                                                    'of AL '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs '\n",
      "                                                                    'such that '\n",
      "                                                                    'positive '\n",
      "                                                                    'and '\n",
      "                                                                    'negative '\n",
      "                                                                    'latter '\n",
      "                                                                    'events '\n",
      "                                                                    'were '\n",
      "                                                                    'equal in '\n",
      "                                                                    'size. We '\n",
      "                                                                    'also '\n",
      "                                                                    'sampled '\n",
      "                                                                    'event '\n",
      "                                                                    'pairs for '\n",
      "                                                                    'each of '\n",
      "                                                                    'CA and CO '\n",
      "                                                                    'such that '\n",
      "                                                                    'it was '\n",
      "                                                                    'five '\n",
      "                                                                    'times '\n",
      "                                                                    'larger '\n",
      "                                                                    'than AL. '\n",
      "                                                                    'The '\n",
      "                                                                    'results '\n",
      "                                                                    'are shown '\n",
      "                                                                    'in Table '\n",
      "                                                                    'TABREF16.'],\n",
      "                                                    'extractive_spans': [   '100 '\n",
      "                                                                            'million '\n",
      "                                                                            'sentences'],\n",
      "                                                    'free_form_answer': '',\n",
      "                                                    'highlighted_evidence': [   'As '\n",
      "                                                                                'a '\n",
      "                                                                                'raw '\n",
      "                                                                                'corpus, '\n",
      "                                                                                'we '\n",
      "                                                                                'used '\n",
      "                                                                                'a '\n",
      "                                                                                'Japanese '\n",
      "                                                                                'web '\n",
      "                                                                                'corpus '\n",
      "                                                                                'that '\n",
      "                                                                                'was '\n",
      "                                                                                'compiled '\n",
      "                                                                                'through '\n",
      "                                                                                'the '\n",
      "                                                                                'procedures '\n",
      "                                                                                'proposed '\n",
      "                                                                                'by '\n",
      "                                                                                'BIBREF13. ',\n",
      "                                                                                'From '\n",
      "                                                                                'the '\n",
      "                                                                                'corpus '\n",
      "                                                                                'of '\n",
      "                                                                                'about '\n",
      "                                                                                '100 '\n",
      "                                                                                'million '\n",
      "                                                                                'sentences, '\n",
      "                                                                                'we '\n",
      "                                                                                'obtained '\n",
      "                                                                                '1.4 '\n",
      "                                                                                'millions '\n",
      "                                                                                'event '\n",
      "                                                                                'pairs '\n",
      "                                                                                'for '\n",
      "                                                                                'AL, '\n",
      "                                                                                '41 '\n",
      "                                                                                'millions '\n",
      "                                                                                'for '\n",
      "                                                                                'CA, '\n",
      "                                                                                'and '\n",
      "                                                                                '6 '\n",
      "                                                                                'millions '\n",
      "                                                                                'for '\n",
      "                                                                                'CO.'],\n",
      "                                                    'unanswerable': False,\n",
      "                                                    'yes_no': None}],\n",
      "                                  'worker_id': [   'c1018a31c3272ce74964a3280069f62f314a1a58']}],\n",
      "               'nlp_background': [   'two',\n",
      "                                     'two',\n",
      "                                     'two',\n",
      "                                     'two',\n",
      "                                     'zero',\n",
      "                                     'zero',\n",
      "                                     'zero',\n",
      "                                     'zero',\n",
      "                                     'zero'],\n",
      "               'paper_read': [   'no',\n",
      "                                 'no',\n",
      "                                 'no',\n",
      "                                 'no',\n",
      "                                 'no',\n",
      "                                 'no',\n",
      "                                 'no',\n",
      "                                 'no',\n",
      "                                 'no'],\n",
      "               'question': [   'What is the seed lexicon?',\n",
      "                               'What are the results?',\n",
      "                               'How are relations used to propagate polarity?',\n",
      "                               'How big is the Japanese data?',\n",
      "                               'What are labels available in dataset for '\n",
      "                               'supervision?',\n",
      "                               'How big are improvements of supervszed '\n",
      "                               'learning results trained on smalled labeled '\n",
      "                               'data enhanced with proposed approach copared '\n",
      "                               'to basic approach?',\n",
      "                               'How does their model learn using mostly raw '\n",
      "                               'data?',\n",
      "                               'How big is seed lexicon used for training?',\n",
      "                               'How large is raw corpus used for training?'],\n",
      "               'question_id': [   '753990d0b621d390ed58f20c4d9e4f065f0dc672',\n",
      "                                  '9d578ddccc27dd849244d632dd0f6bf27348ad81',\n",
      "                                  '02e4bf719b1a504e385c35c6186742e720bcb281',\n",
      "                                  '44c4bd6decc86f1091b5fc0728873d9324cdde4e',\n",
      "                                  '86abeff85f3db79cf87a8c993e5e5aa61226dc98',\n",
      "                                  'c029deb7f99756d2669abad0a349d917428e9c12',\n",
      "                                  '39f8db10d949c6b477fa4b51e7c184016505884f',\n",
      "                                  'd0bc782961567dc1dd7e074b621a6d6be44bb5b4',\n",
      "                                  'a592498ba2fac994cd6fad7372836f0adb37e22a'],\n",
      "               'question_writer': [   'c1fbdd7a261021041f75fbe00a55b4c386ebbbb4',\n",
      "                                      'c1fbdd7a261021041f75fbe00a55b4c386ebbbb4',\n",
      "                                      'c1fbdd7a261021041f75fbe00a55b4c386ebbbb4',\n",
      "                                      'c1fbdd7a261021041f75fbe00a55b4c386ebbbb4',\n",
      "                                      '258ee4069f740c400c0049a2580945a1cc7f044c',\n",
      "                                      '258ee4069f740c400c0049a2580945a1cc7f044c',\n",
      "                                      '258ee4069f740c400c0049a2580945a1cc7f044c',\n",
      "                                      '258ee4069f740c400c0049a2580945a1cc7f044c',\n",
      "                                      '258ee4069f740c400c0049a2580945a1cc7f044c'],\n",
      "               'search_query': ['', '', '', '', '', '', '', '', ''],\n",
      "               'topic_background': [   'unfamiliar',\n",
      "                                       'unfamiliar',\n",
      "                                       'unfamiliar',\n",
      "                                       'unfamiliar',\n",
      "                                       'unfamiliar',\n",
      "                                       'unfamiliar',\n",
      "                                       'unfamiliar',\n",
      "                                       'unfamiliar',\n",
      "                                       'unfamiliar']},\n",
      "    'title': 'Minimally Supervised Learning of Affective Events Using '\n",
      "             'Discourse Relations'}\n"
     ]
    }
   ],
   "source": [
    "qasper = load_dataset(\"allenai/qasper\")\n",
    "print(qasper.keys())\n",
    "pp.pprint(qasper['train'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T12:00:38.457968900Z",
     "start_time": "2024-02-24T12:00:35.907871600Z"
    }
   },
   "id": "c9e16196258215ac",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 1911.10742\n",
      "<class 'str'> 1904.09131\n",
      "<class 'str'> 1611.06322\n",
      "<class 'str'> 1604.02038\n",
      "<class 'str'> 1911.04474\n",
      "<class 'str'> 1905.00840\n",
      "<class 'str'> 1810.02229\n",
      "<class 'str'> 1909.00091\n",
      "<class 'str'> 1909.04387\n",
      "<class 'str'> 2003.13016\n"
     ]
    }
   ],
   "source": [
    "# get the first 10 ids from test split\n",
    "for i in range(10):\n",
    "    print(type(qasper['test'][i]['id']), qasper['test'][i]['id'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T12:15:12.706280800Z",
     "start_time": "2024-02-24T12:15:12.673341500Z"
    }
   },
   "id": "c9c177b5079b9708",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'title', 'abstract', 'full_text', 'qas', 'figures_and_tables'])\n"
     ]
    }
   ],
   "source": [
    "print(qasper['train'][0].keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:54:40.627572900Z",
     "start_time": "2024-02-24T10:54:40.612458900Z"
    }
   },
   "id": "ad4d9a33adf8f42c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['section_name', 'paragraphs'])\n"
     ]
    }
   ],
   "source": [
    "print(qasper['train'][0]['full_text'].keys())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T12:26:28.732393200Z",
     "start_time": "2024-02-24T12:26:28.714388400Z"
    }
   },
   "id": "d9757ae04a1f6d22",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "21\n",
      "4 5 1 4 3 2 2 2 8 1 1 5 11 4 12 2 1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "print(len(qasper['train'][0]['full_text']['paragraphs']))\n",
    "print(len(qasper['train'][0]['full_text']['section_name']))\n",
    "print(*[len(p) for p in qasper['train'][0]['full_text']['paragraphs']])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T12:28:13.059113700Z",
     "start_time": "2024-02-24T12:28:13.043288100Z"
    }
   },
   "id": "f8806a73284b5969",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['question', 'question_id', 'nlp_background', 'topic_background', 'paper_read', 'search_query', 'question_writer', 'answers'])\n"
     ]
    }
   ],
   "source": [
    "print(qasper['train'][0]['qas'].keys())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:55:25.450106500Z",
     "start_time": "2024-02-24T10:55:25.434033500Z"
    }
   },
   "id": "7eca569c8b759464",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['answer', 'annotation_id', 'worker_id'])\n"
     ]
    }
   ],
   "source": [
    "print(qasper['train'][0]['qas']['answers'][0].keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:56:54.303766800Z",
     "start_time": "2024-02-24T10:56:54.287762900Z"
    }
   },
   "id": "29ee67eb93500187",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['unanswerable', 'extractive_spans', 'yes_no', 'free_form_answer', 'evidence', 'highlighted_evidence'])\n",
      "{'unanswerable': False, 'extractive_spans': [], 'yes_no': None, 'free_form_answer': 'a vocabulary of positive and negative predicates that helps determine the polarity score of an event', 'evidence': ['The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event. We expect the model to automatically learn complex phenomena through label propagation. Based on the availability of scores and the types of discourse relations, we classify the extracted event pairs into the following three types.'], 'highlighted_evidence': ['The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event.', 'It is a ']}\n"
     ]
    }
   ],
   "source": [
    "print(qasper['train'][0]['qas']['answers'][0]['answer'][0].keys())\n",
    "print(qasper['train'][0]['qas']['answers'][0]['answer'][0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T10:57:53.695936800Z",
     "start_time": "2024-02-24T10:57:53.681948500Z"
    }
   },
   "id": "49b8e24a0315aa36",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the seed lexicon?\n",
      "{'unanswerable': False, 'extractive_spans': ['seed lexicon consists of positive and negative predicates'], 'yes_no': None, 'free_form_answer': '', 'evidence': ['The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event. We expect the model to automatically learn complex phenomena through label propagation. Based on the availability of scores and the types of discourse relations, we classify the extracted event pairs into the following three types.'], 'highlighted_evidence': ['The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event.']}\n"
     ]
    }
   ],
   "source": [
    "# print the first answer that has an extractive_spans of more than length 0\n",
    "done = False\n",
    "for case in qasper['train']:\n",
    "    for answer in case['qas']['answers']:\n",
    "        for span in answer['answer']:\n",
    "            if len(span['extractive_spans']) > 0:\n",
    "                print(case['qas']['question'][case['qas']['answers'].index(answer)])\n",
    "                print(span)\n",
    "                done = True\n",
    "                break\n",
    "        if done:\n",
    "            break\n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T11:12:19.048954900Z",
     "start_time": "2024-02-24T11:12:19.037946600Z"
    }
   },
   "id": "b3e0b81f2e59f3c8",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(load_dataset('eli5', split='train_eli5')[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19bdf9cb61c63d77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(load_dataset('squad', split='train')[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8c084418ff1a401"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(load_dataset('gooaq', split='train')[999])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95c70b96c1fc540c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(load_dataset('hotpot_qa', 'distractor', split='train')[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de9182f76ad76d21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hpqa = load_dataset('hotpot_qa', 'distractor', split='train')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "996cec650caa3a20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pretty print\n",
    "pp.pprint(hpqa[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbe614d7b341ee57"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "newsqa = load_dataset('newsqa', data_dir = '../data/files')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:05:55.683129100Z",
     "start_time": "2023-11-04T23:05:51.656577100Z"
    }
   },
   "id": "30e8ffa8d01eecbf"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'answer_token_ranges': '652:671',\n",
      "    'question': \"for what People just do n't trust their instincts ?\",\n",
      "    'story_id': './cnn/stories/017df5c4fe1e79eb26957ff6a8b4c1e41cd966ac.story',\n",
      "    'story_text': '-LRB- CNN -RRB- -- Decorating in the midst of a financial '\n",
      "                  'recession is not easy . But Thom Filicia , host of the '\n",
      "                  \"Style Network 's `` Dress My Nest , '' author of `` Thom \"\n",
      "                  \"Filicia Style '' and former cast member of `` Queer Eye for \"\n",
      "                  \"the Straight Guy , '' insists that it can be done . `` \"\n",
      "                  'Paint is very affordable . Pick a color that has life and '\n",
      "                  \"personality , '' Thom Filicia says . `` I always tell \"\n",
      "                  \"people , ` Start with what you have . ' Work as much with \"\n",
      "                  'what you have as possible , and then fill in where '\n",
      "                  \"necessary , '' Filicia said . CNN recently asked the design \"\n",
      "                  'guru about decorating on a budget and helpful tips to make '\n",
      "                  'your home look its best . CNN : When you walk into a room '\n",
      "                  \"that you 're going to redesign , where does your mind first \"\n",
      "                  'go ? Thom Filicia : I look at the layout , I look at the '\n",
      "                  'way the space is being used , and I try to figure out what '\n",
      "                  'the best use of the space is ; that it works really well , '\n",
      "                  \"it looks good , that you 're getting the best views , you \"\n",
      "                  \"'re seeing the space , and that you 're getting through the \"\n",
      "                  \"space . CNN : And that 's focusing mainly on furniture ? \"\n",
      "                  'Filicia : That really focuses on all the furniture . You '\n",
      "                  'want to look at where the rug is and where the sofa is and '\n",
      "                  'coffee tables and chairs -- just how the room works . Even '\n",
      "                  \"if it 's great-looking stuff , it sometimes does n't look \"\n",
      "                  'as good as it can look . CNN : What can people on a tight '\n",
      "                  'budget do to rearrange their living room and make it look '\n",
      "                  'better with what they have ? Filicia : Make sure that your '\n",
      "                  'furniture layout works . Make sure that the things you love '\n",
      "                  \"to look at , you 're seeing . Make sure things are n't \"\n",
      "                  'cluttered . Paint is very affordable . Pick a color that '\n",
      "                  'has life and personality . You could do an accent wall '\n",
      "                  'behind your sofa . You could use a low - -LSB- volatile '\n",
      "                  \"organic compound -RSB- paint so it 's environmentally \"\n",
      "                  'friendly . You can use inexpensive up lights . You put them '\n",
      "                  'on either side of a piece of furniture or behind a tree . '\n",
      "                  'You always want to have a Lutron dimmer you plug into the '\n",
      "                  'wall . And then plug your lamps into the Lutron dimmer , '\n",
      "                  'and you can dim the whole room . CNN : As far as '\n",
      "                  'accessories go , like flowers and pillows , where do you '\n",
      "                  'draw the line on too much or not enough ? Filicia : I like '\n",
      "                  'to keep things clean and straightforward . I think one '\n",
      "                  'floral arrangement is usually enough , or maybe a couple '\n",
      "                  'really small cute little ones . Pillows should function . '\n",
      "                  'You want to sit on a sofa and be comfortable . Start with '\n",
      "                  'three : one lumbar in the center and maybe a pair of '\n",
      "                  'pillows left and right . Add a throw , a rug for underfoot '\n",
      "                  '. Those things start to add layers to the room and make it '\n",
      "                  'a little more acoustical . CNN : What are some common '\n",
      "                  'designing rules that people always tend to follow but that '\n",
      "                  'you can actually break ? Filicia : People think that dark '\n",
      "                  'walls make a room smaller . It actually makes the space '\n",
      "                  'bigger . All the corners recede , and it adds a lot of '\n",
      "                  'depth . Also , I think that color definitely adds a lot of '\n",
      "                  \"warmth to spaces . CNN : What 's the most common mistake \"\n",
      "                  \"that people make ? Filicia : People just do n't trust their \"\n",
      "                  \"instincts , and they 're not willing to take a risk . Have \"\n",
      "                  \"fun with it . It 's only decorating . People tend to go \"\n",
      "                  \"with beige and white just because they 're afraid or they \"\n",
      "                  \"do n't want to make a commitment . CNN : If someone had \"\n",
      "                  'just enough money to do one thing in their room , what '\n",
      "                  'would you tell them to focus on ? Filicia : The first thing '\n",
      "                  'you want to really focus on is a great sofa , because it is '\n",
      "                  'really the anchor for the room . In a bedroom , the anchor '\n",
      "                  'piece is your bed . Start with your anchor piece , and that '\n",
      "                  \"'s where you spend your most money . CNN : You have a new \"\n",
      "                  'book out now , is that right ? Filicia : Yup , I have a '\n",
      "                  'book out right now , which is called `` Thom Filicia Style '\n",
      "                  \", '' and it 's a great book . It 's a lot of fun . It 's \"\n",
      "                  'got a lot of great tips in it . It talks about my '\n",
      "                  \"philosophy ; it talks about color and texture . It 's a \"\n",
      "                  'very comprehensive book with case studies . CNN : Can you '\n",
      "                  'give us some tips for making a place eco-friendly on a '\n",
      "                  \"tight budget ? Filicia : It 's very easy to use \"\n",
      "                  'eco-friendly cleaning supplies , environmentally friendly '\n",
      "                  'lighting throughout your house using low wattage or '\n",
      "                  'eco-friendly bulbs . Also , just turning your lights off '\n",
      "                  \"when you 're not in a room ; when you 're brushing your \"\n",
      "                  'teeth not keeping the water running ; taking shorter '\n",
      "                  'showers . These are all really simple , easy ways that we '\n",
      "                  'can all help Mother Earth repair and heal and replenish '\n",
      "                  'itself .'}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(newsqa['test'][2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:05:56.583872300Z",
     "start_time": "2023-11-04T23:05:56.575867300Z"
    }
   },
   "id": "f48b7bbaf5ca6899"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'they', \"'re\", 'not', 'willing', 'to', 'take', 'a', 'risk', '.', 'Have', 'fun', 'with', 'it', '.', 'It', \"'s\", 'only', 'decorating']\n"
     ]
    }
   ],
   "source": [
    "print(newsqa['test'][2]['story_text'].split()[652:671])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:13:24.008735800Z",
     "start_time": "2023-11-04T23:13:23.998161500Z"
    }
   },
   "id": "62f675dd07dd850f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-LRB- CNN -RRB- -- Decorating in the midst of a financial recession is not easy . But Thom Filicia , host of the Style Network 's `` Dress My Nest , '' author of `` Thom Filicia Style '' and former cast member of `` Queer Eye for the Straight Guy , '' insists that it can be done . `` Paint is very affordable . Pick a color that has life and personality , '' Thom Filicia says . `` I always tell people , ` Start with what you have . ' Work as much with what you have as possible , and then fill in where necessary , '' Filicia said . CNN recently asked the design guru about decorating on a budget and helpful tips to make your home look its best . CNN : When you walk into a room that you 're going to redesign , where does your mind first go ? Thom Filicia : I look at the layout , I look at the way the space is being used , and I try to figure out what the best use of the space is ; that it works really well , it looks good , that you 're getting the best views , you 're seeing the space , and that you 're getting through the space . CNN : And that 's focusing mainly on furniture ? Filicia : That really focuses on all the furniture . You want to look at where the rug is and where the sofa is and coffee tables and chairs -- just how the room works . Even if it 's great-looking stuff , it sometimes does n't look as good as it can look . CNN : What can people on a tight budget do to rearrange their living room and make it look better with what they have ? Filicia : Make sure that your furniture layout works . Make sure that the things you love to look at , you 're seeing . Make sure things are n't cluttered . Paint is very affordable . Pick a color that has life and personality . You could do an accent wall behind your sofa . You could use a low - -LSB- volatile organic compound -RSB- paint so it 's environmentally friendly . You can use inexpensive up lights . You put them on either side of a piece of furniture or behind a tree . You always want to have a Lutron dimmer you plug into the wall . And then plug your lamps into the Lutron dimmer , and you can dim the whole room . CNN : As far as accessories go , like flowers and pillows , where do you draw the line on too much or not enough ? Filicia : I like to keep things clean and straightforward . I think one floral arrangement is usually enough , or maybe a couple really small cute little ones . Pillows should function . You want to sit on a sofa and be comfortable . Start with three : one lumbar in the center and maybe a pair of pillows left and right . Add a throw , a rug for underfoot . Those things start to add layers to the room and make it a little more acoustical . CNN : What are some common designing rules that people always tend to follow but that you can actually break ? Filicia : People think that dark walls make a room smaller . It actually makes the space bigger . All the corners recede , and it adds a lot of depth . Also , I think that color definitely adds a lot of warmth to spaces . CNN : What 's the most common mistake that people make ? Filicia : People just do n't trust their instincts , and they 're not willing to take a risk . Have fun with it . It 's only decorating . People tend to go with beige and white just because they 're afraid or they do n't want to make a commitment . CNN : If someone had just enough money to do one thing in their room , what would you tell them to focus on ? Filicia : The first thing you want to really focus on is a great sofa , because it is really the anchor for the room . In a bedroom , the anchor piece is your bed . Start with your anchor piece , and that 's where you spend your most money . CNN : You have a new book out now , is that right ? Filicia : Yup , I have a book out right now , which is called `` Thom Filicia Style , '' and it 's a great book . It 's a lot of fun . It 's got a lot of great tips in it . It talks about my philosophy ; it talks about color and texture . It 's a very comprehensive book with case studies . CNN : Can you give us some tips for making a place eco-friendly on a tight budget ? Filicia : It 's very easy to use eco-friendly cleaning supplies , environmentally friendly lighting throughout your house using low wattage or eco-friendly bulbs . Also , just turning your lights off when you 're not in a room ; when you 're brushing your teeth not keeping the water running ; taking shorter showers . These are all really simple , easy ways that we can all help Mother Earth repair and heal and replenish itself .\n"
     ]
    }
   ],
   "source": [
    "print(newsqa['test'][2]['story_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T23:13:27.250180900Z",
     "start_time": "2023-11-04T23:13:27.235175800Z"
    }
   },
   "id": "202235e3a1b99e21"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5126\n",
      "637\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                   story_text         \\\n                                                        count unique   \nstory_id                                                               \n./cnn/stories/005670c4a85a3122965180585a8868269...          9      1   \n./cnn/stories/00eaf1c06f1e3ecd48160b43f3b3cd196...          7      1   \n./cnn/stories/017df5c4fe1e79eb26957ff6a8b4c1e41...          7      2   \n./cnn/stories/01ffaf507a54d354ecbbe4a7658d60a2e...          3      2   \n./cnn/stories/02311be4aab97a81d2262963896b975c2...         12      1   \n...                                                       ...    ...   \n./cnn/stories/fcd31a94623303cfb9ee19976f9f3b1dc...         12      1   \n./cnn/stories/fe4c002023451791f364f4030e40eac18...          9      1   \n./cnn/stories/ff671b6dd9be9cbc9d44cc68b82889602...          7      2   \n./cnn/stories/ff6af554bf69b47f857da6275f24c0878...          7      1   \n./cnn/stories/ffb0c441ab15bc7c87856aff293ac2728...          7      1   \n\n                                                                                                       \\\n                                                                                                  top   \nstory_id                                                                                                \n./cnn/stories/005670c4a85a3122965180585a8868269...  -LRB- CNN -RRB- -- A rebel group in the Democr...   \n./cnn/stories/00eaf1c06f1e3ecd48160b43f3b3cd196...  ATHENS , Georgia -LRB- CNN -RRB- -- Over the r...   \n./cnn/stories/017df5c4fe1e79eb26957ff6a8b4c1e41...  -LRB- CNN -RRB- -- Decorating in the midst of ...   \n./cnn/stories/01ffaf507a54d354ecbbe4a7658d60a2e...  -LRB- CNN -RRB- -- A Saudi Arabian blogger det...   \n./cnn/stories/02311be4aab97a81d2262963896b975c2...  HANNOVER , Germany -- Germany maintained the p...   \n...                                                                                               ...   \n./cnn/stories/fcd31a94623303cfb9ee19976f9f3b1dc...  LIMA , Peru -LRB- CNN -RRB- -- Tensions betwee...   \n./cnn/stories/fe4c002023451791f364f4030e40eac18...  WASHINGTON -LRB- CNN -RRB- -- As President Oba...   \n./cnn/stories/ff671b6dd9be9cbc9d44cc68b82889602...  -LRB- CNN -RRB- -- Archaeologists in Israel ha...   \n./cnn/stories/ff6af554bf69b47f857da6275f24c0878...  WASHINGTON -LRB- CNN -RRB- -- The United State...   \n./cnn/stories/ffb0c441ab15bc7c87856aff293ac2728...  WASHINGTON -LRB- CNN -RRB- -- The government i...   \n\n                                                        question         \\\n                                                   freq    count unique   \nstory_id                                                                  \n./cnn/stories/005670c4a85a3122965180585a8868269...    9        9      9   \n./cnn/stories/00eaf1c06f1e3ecd48160b43f3b3cd196...    7        7      7   \n./cnn/stories/017df5c4fe1e79eb26957ff6a8b4c1e41...    6        7      7   \n./cnn/stories/01ffaf507a54d354ecbbe4a7658d60a2e...    2        3      3   \n./cnn/stories/02311be4aab97a81d2262963896b975c2...   12       12     12   \n...                                                 ...      ...    ...   \n./cnn/stories/fcd31a94623303cfb9ee19976f9f3b1dc...   12       12     12   \n./cnn/stories/fe4c002023451791f364f4030e40eac18...    9        9      9   \n./cnn/stories/ff671b6dd9be9cbc9d44cc68b82889602...    6        7      7   \n./cnn/stories/ff6af554bf69b47f857da6275f24c0878...    7        7      7   \n./cnn/stories/ffb0c441ab15bc7c87856aff293ac2728...    7        7      7   \n\n                                                                                                       \\\n                                                                                                  top   \nstory_id                                                                                                \n./cnn/stories/005670c4a85a3122965180585a8868269...              What is the name of the rebel group ?   \n./cnn/stories/00eaf1c06f1e3ecd48160b43f3b3cd196...  What can be turned into valuable , renewable r...   \n./cnn/stories/017df5c4fe1e79eb26957ff6a8b4c1e41...  for what People just do n't trust their instin...   \n./cnn/stories/01ffaf507a54d354ecbbe4a7658d60a2e...                                   who was detained   \n./cnn/stories/02311be4aab97a81d2262963896b975c2...                             Who did Germany beat ?   \n...                                                                                               ...   \n./cnn/stories/fcd31a94623303cfb9ee19976f9f3b1dc...  Where did Gen. Donayre make anti-Chile comments ?   \n./cnn/stories/fe4c002023451791f364f4030e40eac18...       Obama 's approval rating in January was what   \n./cnn/stories/ff671b6dd9be9cbc9d44cc68b82889602...          What do the details suggest the bust is ?   \n./cnn/stories/ff6af554bf69b47f857da6275f24c0878...         What would the U.S. share under the deal ?   \n./cnn/stories/ffb0c441ab15bc7c87856aff293ac2728...                  what is the labeling change for >   \n\n                                                        answer_token_ranges  \\\n                                                   freq               count   \nstory_id                                                                      \n./cnn/stories/005670c4a85a3122965180585a8868269...    1                   9   \n./cnn/stories/00eaf1c06f1e3ecd48160b43f3b3cd196...    1                   7   \n./cnn/stories/017df5c4fe1e79eb26957ff6a8b4c1e41...    1                   7   \n./cnn/stories/01ffaf507a54d354ecbbe4a7658d60a2e...    1                   3   \n./cnn/stories/02311be4aab97a81d2262963896b975c2...    1                  12   \n...                                                 ...                 ...   \n./cnn/stories/fcd31a94623303cfb9ee19976f9f3b1dc...    1                  12   \n./cnn/stories/fe4c002023451791f364f4030e40eac18...    1                   9   \n./cnn/stories/ff671b6dd9be9cbc9d44cc68b82889602...    1                   7   \n./cnn/stories/ff6af554bf69b47f857da6275f24c0878...    1                   7   \n./cnn/stories/ffb0c441ab15bc7c87856aff293ac2728...    1                   7   \n\n                                                                         \n                                                   unique      top freq  \nstory_id                                                                 \n./cnn/stories/005670c4a85a3122965180585a8868269...      7    48:55    2  \n./cnn/stories/00eaf1c06f1e3ecd48160b43f3b3cd196...      7    48:53    1  \n./cnn/stories/017df5c4fe1e79eb26957ff6a8b4c1e41...      6    20:51    2  \n./cnn/stories/01ffaf507a54d354ecbbe4a7658d60a2e...      3    49:51    1  \n./cnn/stories/02311be4aab97a81d2262963896b975c2...     10    37:38    2  \n...                                                   ...      ...  ...  \n./cnn/stories/fcd31a94623303cfb9ee19976f9f3b1dc...     10  183:184    2  \n./cnn/stories/fe4c002023451791f364f4030e40eac18...      7  110:112    2  \n./cnn/stories/ff671b6dd9be9cbc9d44cc68b82889602...      7    16:25    1  \n./cnn/stories/ff6af554bf69b47f857da6275f24c0878...      6  148:150    2  \n./cnn/stories/ffb0c441ab15bc7c87856aff293ac2728...      7    14:15    1  \n\n[637 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">story_text</th>\n      <th colspan=\"4\" halign=\"left\">question</th>\n      <th colspan=\"4\" halign=\"left\">answer_token_ranges</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n    <tr>\n      <th>story_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>./cnn/stories/005670c4a85a3122965180585a88682692b8d1b9.story</th>\n      <td>9</td>\n      <td>1</td>\n      <td>-LRB- CNN -RRB- -- A rebel group in the Democr...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>What is the name of the rebel group ?</td>\n      <td>1</td>\n      <td>9</td>\n      <td>7</td>\n      <td>48:55</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>./cnn/stories/00eaf1c06f1e3ecd48160b43f3b3cd196a319c8a.story</th>\n      <td>7</td>\n      <td>1</td>\n      <td>ATHENS , Georgia -LRB- CNN -RRB- -- Over the r...</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>What can be turned into valuable , renewable r...</td>\n      <td>1</td>\n      <td>7</td>\n      <td>7</td>\n      <td>48:53</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>./cnn/stories/017df5c4fe1e79eb26957ff6a8b4c1e41cd966ac.story</th>\n      <td>7</td>\n      <td>2</td>\n      <td>-LRB- CNN -RRB- -- Decorating in the midst of ...</td>\n      <td>6</td>\n      <td>7</td>\n      <td>7</td>\n      <td>for what People just do n't trust their instin...</td>\n      <td>1</td>\n      <td>7</td>\n      <td>6</td>\n      <td>20:51</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>./cnn/stories/01ffaf507a54d354ecbbe4a7658d60a2e553e1d8.story</th>\n      <td>3</td>\n      <td>2</td>\n      <td>-LRB- CNN -RRB- -- A Saudi Arabian blogger det...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>who was detained</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>49:51</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>./cnn/stories/02311be4aab97a81d2262963896b975c27f6503d.story</th>\n      <td>12</td>\n      <td>1</td>\n      <td>HANNOVER , Germany -- Germany maintained the p...</td>\n      <td>12</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Who did Germany beat ?</td>\n      <td>1</td>\n      <td>12</td>\n      <td>10</td>\n      <td>37:38</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>./cnn/stories/fcd31a94623303cfb9ee19976f9f3b1dc519efd5.story</th>\n      <td>12</td>\n      <td>1</td>\n      <td>LIMA , Peru -LRB- CNN -RRB- -- Tensions betwee...</td>\n      <td>12</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Where did Gen. Donayre make anti-Chile comments ?</td>\n      <td>1</td>\n      <td>12</td>\n      <td>10</td>\n      <td>183:184</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>./cnn/stories/fe4c002023451791f364f4030e40eac18a8fcb00.story</th>\n      <td>9</td>\n      <td>1</td>\n      <td>WASHINGTON -LRB- CNN -RRB- -- As President Oba...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>Obama 's approval rating in January was what</td>\n      <td>1</td>\n      <td>9</td>\n      <td>7</td>\n      <td>110:112</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>./cnn/stories/ff671b6dd9be9cbc9d44cc68b828896021cc5be5.story</th>\n      <td>7</td>\n      <td>2</td>\n      <td>-LRB- CNN -RRB- -- Archaeologists in Israel ha...</td>\n      <td>6</td>\n      <td>7</td>\n      <td>7</td>\n      <td>What do the details suggest the bust is ?</td>\n      <td>1</td>\n      <td>7</td>\n      <td>7</td>\n      <td>16:25</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>./cnn/stories/ff6af554bf69b47f857da6275f24c0878c1ecd3a.story</th>\n      <td>7</td>\n      <td>1</td>\n      <td>WASHINGTON -LRB- CNN -RRB- -- The United State...</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>What would the U.S. share under the deal ?</td>\n      <td>1</td>\n      <td>7</td>\n      <td>6</td>\n      <td>148:150</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>./cnn/stories/ffb0c441ab15bc7c87856aff293ac2728394957b.story</th>\n      <td>7</td>\n      <td>1</td>\n      <td>WASHINGTON -LRB- CNN -RRB- -- The government i...</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>what is the labeling change for &gt;</td>\n      <td>1</td>\n      <td>7</td>\n      <td>7</td>\n      <td>14:15</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>637 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(newsqa['test']))\n",
    "print(len({case[\"story_id\"] for case in newsqa['test']}))\n",
    "# pandas describe cases per story\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(newsqa['test'])\n",
    "df.groupby('story_id').describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T20:48:30.293181900Z",
     "start_time": "2023-11-01T20:48:28.868990300Z"
    }
   },
   "id": "745ce2487450edd1"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3734.454155286773\n"
     ]
    }
   ],
   "source": [
    "# average length of stories\n",
    "import numpy as np\n",
    "print(np.mean([len(story['story_text']) for story in newsqa['test']]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:02:22.973075800Z",
     "start_time": "2023-11-01T21:02:22.802691900Z"
    }
   },
   "id": "7d5d8b919ee258df"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T21:24:07.312277800Z",
     "start_time": "2023-12-06T21:24:06.668756700Z"
    }
   },
   "id": "e10afabbc9247262"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
